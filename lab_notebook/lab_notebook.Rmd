---
title: "R Notebook for MSDepression Project"
output:
  html_notebook
---

#### 20201008

First, need to summarize data

1) Got data into csv format
  - Opened /Users/eballer/Documents/Penn T32/MS_Depression_Ted_Taki/Documents/*xls in excel and saved as csv
2)
```{move_data bash}
cd /Users/eballer/BBL/msdepression/data/
mkdir dac
cp /Users/eballer/Documents/Penn T32/MS_Depression_Ted_Taki/Documents/*csv .
```

3) In R, started /Users/eballer/BBL/msdepression/dac_summary.Rmd to summarize data

** during the last iteration of de-identifying the DAC, the PHQ-9 scores all vanished. Will need to ask for them to be re-added.
** also, number of people dropped by 50% (from 36277 to 16383)

#### 20201012

Continued with descriptives

  - Read in Melissa's data sheet.
  - subsetted EMPI and Accession # (since our EMPI's are deidentified)
  - Merged with my datasheet on Accession #
  - "PatientID == EMPI"

Merged Melissa's data with mine to get empis.

#### 20201013

[x] Figure out how many people with repeat mrns - to remove doubles. Will need to remove duplicates.

#### 20201027

Going back and forth a lot with DAC people, should have a new update soon. Big thing will be to parse PHQ2/9. We will get all of them but have to tie them to their appropriate scans


#### 20201117

Lots of back and forth with DAC, significantly less people in my pull that limited its pull to people who had G35 codes only. Went back to emails with Sunil (Taki involved). See email below.

---

I think my focus was more on the images and using the challenging radiology data.
So I took a quick look at the codes and files that I might have sent or used. Unfortunately, I canâ€™t remember what the last file I sent was and I donâ€™t have access to the lothal drive anymore.
 
Criteria:
Donâ€™t see any dates used. Guessing data probably was up to 7/2018(around the time I ran the report)
I looked for patients with order associated diagnosis (%340% or %G35%)  which we mentioned that it is something that is not always populated.
And specific proc codes or cpt codes:
-          '70551','70552','70553','MHDI', 'IMGMR0128','IMGMR0047','IMGMR0061','IMGMR0054','70551','70552','70553','MHDI', 'IMGMR0128','IMGMR0047','IMGMR0061','IMGMR0054'
Performing Depts: 361, 547, 6004, 6013
 
--If I remember correctly, we added additional proc code and cpt codes in because the data output was very low and associated diagnosis was not always populated. Also, Taki, Melissa and I talked about some of the possible discrepancies. Which was really helpful.
 
Recommendation: I recommend taking a couple patients and looking at their records.
 
For ex: I reviewed a patient: Zylstra, Whitney
I donâ€™t see any ms diagnosis on the main snapshot problem list on the chart and started assuming she doesnâ€™t have MS.
I looked further and found that there was a procedure encounter diag on 9/11/2017 with diag of â€œG35â€.

 
But if you look at the orders, I found a couple orders with the procode listed above but the associated diagnosis was not 340 or G35. Iâ€™m not clinical and I could be wrong but I would think this patient would be on your report.
 
Thanks
Sunil
 
cid:image001.gif@01D291AA.9A09B140
Sunil Thomas
Senior Clinical Information Analyst
(: 215-662-4784
ðŸ“§: Sunil.Thomas@pennmedicine.upenn.edu
 
â€œBe water, my friend.â€
 
This is the best I have for now guys. I hope this helps!

---

#### 20210126

A lot of success. Went back and forth with DAC, decided to ask for basically everyone, and we would post sort for providers that were associated with MS clinic, assuming that patients who received a diagnosis of MS from one of these people actually had it. 

Updates dac_summary to include not only a summary of the returned DAC pull, but also of the subset of people with MS providers. dac_summary.Rmd can be found on github, and summary table on: https://docs.google.com/presentation/d/1pDWXYUmq6sq7Xe08HaWdxLELa-qtQtABCw8RIIZ_7to/edit#slide=id.gb446eacf6a_0_0

#### 20210129

[x] figure out who has unique icd9/10 and phq2/9
[x] figure out what the overlap in # of scans between Melissa and my new group are

#### 20210208
[x] check logic of unique EMPIs, looks like something wonky is going on - less unique empis in my group than in the overlap group. Obviously they should be the same if not better
   - fixed, using accession #s and not empis to look for unique empis. Now that I look for unique EMPIs, we are all good!
   
#### 20210209
[x] post to channel tomorrow

#### 20210223
[x] Melissa caught that one of our MS providers was in incorrectly. This added a bunch of scans. JACOBS, DINA A. is the right person, not JACOBS, LINDA. Reran my stuff and updated my ms google doc.

Mellisa also realized that our group should include those with a visit with an MS provider AND ICD9/10 MS code.

Today:
3737 patients
28348 total accession numbers
17038 accession numbers we donâ€™t already have and will be requesting
3737 unique empis from the new pull who have seen an MS attending with a corresponding MS diagnosis


#### The future
-at some point, will have to make sure to clarify we used ms diagnoses and the ms provider for our final #s

#### 20210421

- Have been summarizing MS data and some interesting findings are coming about: 
1] "Number of unique procedure names (ie. MRI Head w/out contrast; MRI Source Images): 10"
[1] "Number of unique department names (ie. RAD HUP PCAM Ground): 3"
[1] "Number of unique modalities (ie. HUP PCAM GR MR4 3T; MR6 3T): 11"
[1] "Number of unique accession #s n= 16830"
[1] "Number of unique EMPIS n = 3737"
[1] "N PHQ-2 = 4606; n = 130 meeting criteria for depression (PHQ2) >= 3"
[1] "N PHQ-9 = 261; noDep/mild/mod/mod-severe/severe = 77/73/65/21/25"
[1] "num people with both phq2 and 9 = 0"
[1] "N with phq2 (Unique EMPI) n = 899 out of 4606; n - 32 meeting criteria for depression (PHQ2) >= 3"
[1] "N with phq9 (Unique EMPI) n = 68 out of 261; noDep/mild/mod/mod-severe/severe = 18/16/18/8/8"
[1] "N with ICD 9/10 codes for depression = 2123"
[1] "N with ICD 9/10 codes for depression and unique EMPI = 493 out of 16830"
[1] "N with ICD 9/10 codes for depression and phq2 (ALL SCANS) = 960 out of 2123"
[1] "N with ICD 9/10 codes for depression and phq9 (ALL SCANS) = 140 out of 2123"
[1] "N dep + PHQ-2 = 960; n = 83 meeting criteria for depression (PHQ2) >= 3"
[1] "N dep + PHQ-9 = 140; noDep/mild/mod/mod-severe/severe = 22/39/44/20/15"
[1] "N with ICD 9/10 codes for depression and phq2 (unique) = 201 out of 2123"
[1] "N with ICD 9/10 codes for depression and phq9 (unique) = 43 out of 2123"
[1] "N without Depression/ICD 9/10 codes for healthy = 14707"
[1] "N without Depression/ ICD 9/10 codes for healthy and unique EMPI = 3244 out of 14707"
[1] "N without Depression/ ICD 9/10 codes for healthy and phq2 (ALL SCANS) = 3646 out of 14707"
[1] "N healthy w/PHQ-2 = 3646; n = 47 meeting criteria for depression (PHQ2) >= 3"
[1] "N without Depression/ ICD 9/10 codes for healthy and phq9 (ALL SCANS) = 121 out of 14707"
[1] "N healthy w/PHQ-9 = 121; noDep/mild/mod/mod-severe/severe = 55/34/21/1/10"
[1] "N without Depression/ ICD 9/10 codes for healthy and phq2 (unique) = 698 out of 14707"
[1] "N without Depression/ ICD 9/10 codes for healthy and phq9 (unique) = 25 out of 14707"

- Starting to look at statistical relationships as well

- takeaways. ~12% of people have a chart dx of MS, even though the literature says much more
   - PHQ2 and phq9s characterize MS differently. On average, people are not depressed (PHQ2 ~ 0.5), but are mildly depressed with (PHQ9 ~9). What does this mean?
   - PHQ9s include 7 more qs than 2s, including a lot of somatic symptoms (fatigue, appetite, psychomotor agitation/retardation)
   
- To dos:
  [] Chi sq comparing frequency of depression dx by phq2s vs phq9s
  [] Finding out if there is some sort of a time where some people got phq2s at some point, and some got phq9s -> is there a reason? Same population, different results
  [] literature review of ms depression, understand how depression was previously dx/described; n's, any explanation for somatic sxs?
      - does depression get better with MS tx? Suggesting that MS depression dx could have a lot to do with somatic stuff
      - Another thought - if PHQ9 is pos, but 2 is negative, even though we don't have indiv measures, it is actually splitting out anhedonia from other depressive sxs, which is interesting
  [x] lit search on evidence behind phq2 and 9
  [x] matt schindler meeting
    - to prepare 10 minute summary of the research I've reviewed
       - what has been done
       - what is the state of the field?
    - summary of our sample so far
    - prelim analyses and qs
    - Ask: are there markers of progression in the literature or that you use? Could we extract from EMR? Or would we need NLP?
    - What do you all notice? ANy differences in depression in pts you start on certain txs versus other than we can test in real world?
  
- also, we do have longitudinal data in a subset, could compare phq2/9 for brains within same subject with more/less MS.


[x] meeting with everyone

#### 20210527

- We are getting really into our collab with harvard and neurology!
- on 5/28, I'll present my work so far. For visualization purposes, I've used a combo of afni (for masking) and fslview (for visualizing), and dsi studio (for making the WM tracts)

- First, we got a "depression network" from harvard, based on a paper from Shan Siddiqui. It is from a preprint:
https://www.dropbox.com/sh/lj5mbfdsig5e4xa/AABfln6Ma_2ialx_KXNHR0oQa?dl=0

- Next, Matt took this into dsi studio, made his mask, and then ran the fibertracking and got some beautiful pictures

- Then, I took the depression network, masked it with our MNI mask, and did visualization in fslview

- Making the masks (had to do this for my figures because the mask from harvard didn't quite line up with our MNI, so I had to make sure I masked the harvard one with the mni template so it looked pretty)

    3dcalc -a MNI152_T1_2mm_brain.nii.gz -expr 'ispositive(a)' -prefix mni_positive_mask.nii
    3dcalc -a mni_positive_mask.nii -b AllFX_wmean.nii -expr 'a*b' -prefix mni_x_AllFx_mean.nii

- visualizing the overlaps 
  - fslview_deprecated
  - open each of the masks. Make sure the eye is clicked to keep it "on"
  - the info button allows you to change the scale from grey to hot (red)
  - the threshold is at the top. When changing it, make sure you are clicking on the image you want to use

- dsistudio to make the fiber tracks
  - open dsistudio
  - click 3
  - open the image /Users/eballer/BBL/msdepression/templates/dti/1904002815.src.gz.odf8.f5.gqi.1.25.fib.gz
  - Step t3d, click "enable autotrack"
  - click "fibertracking"
  - so pretty!
  - To do special fibers, unhighlight the full brain
    -   Step t3d, select the fiber you want to use
    -   click "fibertracking"
  - To do a region of avoidance, go to step T3a
    -   click the white piece of paper
    - click ROA
    - in t3b, make a box, circle, or whatever on the brain
    - in T3d, click the same fiber tracking button, and now you have only the fibers that were not hit by your cutting!
    - click on and off the two fiber tracts to see what you gain/lose!
    - if you don't like what you have, delete it
    
#### 20210806

- Going to work on algorithm with Matt as Tim reprocesses all of the scans
- Doing this by taking a good, qc'd sample of mimosa, finding a way to register it to T1, and how to register T1 to MNI space (to piggyback lesion maps)
- can do the same with probability maps, though starting with lesion maps (as if they are just rois) could be a good way to start
- Tasks

[x] I need datalad on pmacs
   - so we can put our data here
   - steps:
```{bash}
ssh -Y eballer@sciget.pmacs.upenn.edu
cd ~
source pmacs-setup-project-user.sh # this was copied from the cubic-setup-project-user.sh script per Azeez
```

[x] I need to download hcp data into datalad
 
   
[x] connectomedb account
[x] dsistudio is local
   - use it to test reconstruction
[x] download 3 or 4 hcp scans
- things were going okay and then my dsi studio had a bug. Now I basically need to wait for my new computer to come in.

20210826
  [x] Chi sq comparing frequency of depression dx by phq2s vs phq9s
  [x] Finding out if there is some sort of a time where some people got phq2s at some point, and some got phq9s -> is there a reason? Same population, different results - not really
  [] literature review of ms depression, understand how depression was previously dx/described; n's, any explanation for somatic sxs?
      - does depression get better with MS tx? Suggesting that MS depression dx could have a lot to do with somatic stuff
      - Another thought - if PHQ9 is pos, but 2 is negative, even though we don't have indiv measures, it is actually splitting out anhedonia from other depressive sxs, which is interesting
[x] figure out how to register lesions to hcp scans
[x] ask Phil cook for how he registers older brains (with some WM lesions that can interfere with registration) onto MNI

20211007 
[x] made a script to take lesions (these are hand drawn) and use dsi studio to make subtraction maps. Now all I need are real files!

script: "/Users/eballer/BBL/msdepression/scripts/dsi_studio_bash.sh

```{bash dsi_studio_bash}
#!/bin/bash

#### Welcome to the Region_making party #########
### Pre: Must have a file with full paths to the lesioned data 
### Post: Within each directory specified by the lesioned data, will have a directory that has all tractography (ROA, ROI, Full)
### Uses: For use in MS depression - take a subject's mimosa lesions and generate the fiber tracts (individual fascicles) that run through it
#dependencies: Using dsi studio downloaded 9/2021

export PATH=${PATH}:/Applications/dsi_studio.app/Contents/MacOS/
template='/Users/eballer/BBL/msdepression/templates/dti/HCP1065.1mm.fib.gz'
default='/Users/eballer/BBL/msdepression/data/mimosa_file_paths'
fascicle_directory='/Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography/'

if [ $# == 0 ]
then
    echo "We will use the default mimosa path file" $default
    lesion_file=$default
else  
    lesion_file=$1
fi
echo "File being read is "$lesion_file
echo "... Starting to make lesions ..."

lesion_paths=$(cat $lesion_file)

for lesion in ${lesion_paths}; do
    echo "Working on file" $lesion
    # make directory within parent directory for tracts
    parent_dir=$(echo $lesion | perl -pe s'/(.*)\/.*/$1/g')
    mask_prefix=$(echo $lesion | perl -pe s'/(.*)\/(.*).nii.gz/$2/g')
    if [ ! -d $parent_dir/fiber_tracking_maps ] 
    then
        mkdir $parent_dir/fiber_tracking_maps
    fi

    fiber_bundle_type_list=(
        "association"
        "cerebellum"
        "cranial_nerve"
        "projection"
        "commissural")
    for fiber_bundle_type in "${fiber_bundle_type_list[@]}"; do
        echo "Fiber bundle type is " $fiber_bundle_type
        echo "making directory" $parent_dir/fiber_tracking_maps/$fiber_bundle_type
        mkdir $parent_dir/fiber_tracking_maps/$fiber_bundle_type
        fascicles=$(ls ${fascicle_directory}/${fiber_bundle_type}/*.tt.gz)
        for fascicle in ${fascicles}; do
            echo "Fascicle is  " $fascicle
            fascicle_root_name=$(echo $fascicle | perl -pe s'/(.*)\/(.*).tt.gz/$2/g') 
            dsi_studio --action=ana --source=$template --tract=$fascicle --roa=$lesion --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_lesioned_ROA.tt.gz
            dsi_studio --action=ana --source=$template --tract=$fascicle --roi=$lesion --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_lesioned_ROI.tt.gz
            dsi_studio --action=ana --source=$template --tract=$fascicle --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_full.tt.gz
        done
        # $path/dsi_studio --action=ana --source=/Users/eballer/BBL/msdepression/templates/dti/HCP1065.1mm.fib.gz --tract=/Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography/association/SLF2_R.tt.gz --roa=/Users/eballer/BBL/msdepression/templates/perfect_ms_subject/run-001/mimosa_binary_mask_0.25.nii.gz --output=/Users/eballer/BBL/msdepression/templates/roi_files_for_testing/SLF2R_lesioned_ROA.nii.gz
        # $path/dsi_studio --action=ana --source=/Users/eballer/BBL/msdepression/templates/dti/HCP1065.1mm.fib.gz --tract=/Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography/association/SLF2_R.tt.gz --roi=/Users/eballer/BBL/msdepression/templates/perfect_ms_subject/run-001/mimosa_binary_mask_0.25.nii.gz --output=/Users/eballer/BBL/msdepression/templates/roi_files_for_testing/SLF2R_lesioned_ROI.nii.gz
        # $path/dsi_studio --action=ana --source=/Users/eballer/BBL/msdepression/templates/dti/HCP1065.1mm.fib.gz --tract=/Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography/association/SLF2_R.tt.gz --output=/Users/eballer/BBL/msdepression/templates/roi_files_for_testing/SLF2R_full_ROI.nii.gz
    done
done

```


20211012
 [x] Working on getting a sample MS mimosa output into HCP space
 
    - Perfect subject in MS group
        - T1w: 
        ** with skull
        /Users/eballer/BBL/msdepression/templates/perfect_ms_subject/run-001/t1_n4.nii.gz
        ** skull stripped
        /Users/eballer/BBL/msdepression/templates/perfect_ms_subject/run-001/t1_n4_brain.nii.gz
        ** brainmask
        /Users/eballer/BBL/msdepression/templates/perfect_ms_subject/run-001/t1_n4_brainmask.nii.gz
        - mimosa file: /Users/eballer/BBL/msdepression/templates/perfect_ms_subject/run-001/mimosa_binary_mask_0.25.nii.gz
    - HCP T1 : /Users/eballer/BBL/msdepression/templates/dti/mni_icbm152_nlin_asym_09a/mni_icbm152_t1_tal_nlin_asym_09a.nii
  
  - recommended script from Phil Cook: 
    * antsRegistrationSyN.sh

### ---------- Narrative from Phil and Matt ------    
    If you have raw data, I would do antsBrainExtraction.sh, N4BiasFieldCorrection, then antsRegistrationSyN.sh (brain <-> brain)

Matt Cieslak  10:06 AM
would you do anything differently if you had a mask of small MS lesions?

Phil Cook  10:08 AM
You can mask them out by inverting and then passing mask with -x
10:08
So basically -x (brain_mask - lesions)

Matt Cieslak  10:09 AM
for the masks, we should use the skull-on, n4 image and -xâ€™ed mask from antsBrainExtraction minus the lesions? as input to antsRegistrationSyN.sh (edited) 

Phil Cook  10:10 AM
If the lesions are small, masking them out should be sufficient
10:12
For larger lesions, you can try to impute "normal" tissue in various ways, then do the registration
10:17
There's different strategies for skull on vs off.
Some people use the skull-on image with a tight brain mask in fixed and moving space, to compensate for areas where the brain mask was not expansive enough.
I usually take the skull off, so that bits of skull don't get pulled inside the mask during nonlinear registration, and use a mask that is dilated a bit so that the edge of the brain is not the edge of the mask. Reasoning being that I want small misalignments at the edge of the brain to feature in the metric and its gradients

Matt Cieslak  10:19 AM
ok thatâ€™s what I thought
10:19
Sounds good @Erica Baller?
10:19
thanks as always @Phil Cook!

Erica Baller  10:20 AM
Mostly yes!
10:25
In theory it makes sense - practically a little more challenging. Is there any documentation or script that actually does this kind of thing step by step that I could use to get the more technical pieces?

Phil Cook  10:36 AM
https://github.com/ntustison/antsBrainExtractionExample
https://github.com/stnava/ANTsTutorial
The scripts are not too hard to use. An example N4 call:
N4BiasFieldCorrection -d 3 -i <input> -x <brain mask> -w <brain_mask minus lesions> -s 2 -c  [ 50x50x50x50,0.0000000001 ] -b [ 180 ] -o <output> --verbose 1
ntustison/antsBrainExtractionExample
Stars
4
Language
R
Added by GitHub
stnava/ANTsTutorial
Stars
27
Language
HTML
Added by GitHub
10:37
The trick with -x and -w for N4 is that you can include them in the mask (-x) but exclude them from the bias computation (-w is zero in lesions). This way they won't mess up bias correction but will get corrected. If you exclude voxels from -x, they do not get corrected
10:41
The shrink factor "-s" controls how to downsample the image. This makes the computation faster. For 1mm data I use 2, for sub-1mm data 4. The other parameter of interest is the initial spline spacing 180mm. Every level doubles resolution, so 180x90x45x22.5 . For a more detailed bias field, reduce this number or add an extra level. The default in ANTs scripts is 200 for adult human data, but I have found that bias fields have gotten worse over time, so I typically use 160-180
### --------- Done with excerpted text --------

Making my mask (for brain_mask minus lesions)

```{bash make_substraction_mask}
cd /Users/eballer/BBL/msdepression/templates/erica_created_for_hcp_reg
3dcalc -a t1_n4_brainmask.nii.gz -b mimosa_binary_mask_0.25.nii.gz -expr 'a-b' -prefix t1_n4_brain_minus_mimosa_binary_mask.nii.gz
```

Now Matt is asking if we need to dilate the mask more. 

So I did
```{bash}
3dmask_tool -input t1_n4_brainmask.nii.gz -prefix t1_n4_brainmask_d3.nii.gz -dilate_input 3

3dcalc -a t1_n4_brainmask.nii.gz -b mimosa_binary_mask_0.25.nii.gz -expr 'a-b' -prefix t1_n4_brain_minus_mimosa_binary_mask.nii.gz

3dcalc -a mni_icbm152_t1_tal_nlin_asym_09a.nii -b mni_icbm152_t1_tal_nlin_asym_09a_mask.nii -expr 'a*b' -prefix mni_icbm152_t1_tal_nlin_asym_09axbrainmask.nii
```
 The input going in will be:
 T1w: /Users/eballer/BBL/msdepression/templates/erica_created_for_hcp_reg/t1_n4_brain.nii.gz  
 Mask:/Users/eballer/BBL/msdepression/templates/erica_created_for_hcp_reg/t1_n4_brainmask_d3.nii.gz
 MNI HCP template: /Users/eballer/BBL/msdepression/templates/erica_created_for_hcp_reg/mni_icbm152_t1_tal_nlin_asym_09axbrainmask.nii  
 
 Transferred my directory onto pmacs, where ants should theoretically be
```{bash}
scp -r erica_created_for_hcp_reg/ eballer@transfer.pmacs.upenn.edu:/project/msdepression

ssh -Y eballer@scisub.pmacs.upenn.edu
cd /project/ms
xbash

sh ants_registration_code.sh  

```
 
Current code in ants_registration_code.sh
```{bash}
#!/bin/bash
### ANTS registration for MS Depression
##pre- requires ms patient T1, (eventually their mimosa), mni brain: mni_icbm152_t1_tal_nlin_asym_09a.
nii, mask (currently using the one that was dilated in afni, d3
## 3dmask_tool -input t1_n4_brainmask.nii.gz -prefix t1_n4_brainmask_d3.nii.gz -dilate_input 3
##Post - ms participant T1w registered to icbm_template space (and later mimosa as well)
##Uses - We have all of these great ms depression scans but they are in native space. This will get th
em into mni space so they can be used with HCP templates, both structural and diffusion
##Dependencies: Using ANTs/2.3.5

# Set up paths
#export ANTSPATH=/home/eballer/
#export PATH=${ANTSPATH}:$PATH

#### Run registration

#default T1: t1_n4_brain.nii.gz 
t1=t1_n4_brain.nii.gz 
#default brain mask: t1_n4_brainmask_d3.nii.gz
brain_mask=t1_n4_brainmask_d3.nii.gz
#default target/template hcp brain" mni_icbm152_t1_tal_nlin_asym_09axbrainmask.nii
mni_target_t1=mni_icbm152_t1_tal_nlin_asym_09axbrainmask.nii

#output
outfile_prefix=ms_t1_to_mni_icbm152
antsRegistrationSyN.sh -d 3 -f ${mni_target_t1} -m ${t1} -o ${outfile_prefix} -x ${brain_mask}

#now actually do the transform
mimosa_path=mimosa_binary_mask_0.25.nii.gz #this is from mimosa output
mimosa_mni_hcp_path=mimosa_binary_mask_0.25_mni_hcp.nii.gz #output file prefix
mni_hcp_path=mni_icbm152_t1_tal_nlin_asym_09axbrainmask.nii #template
affine_mat=ms_t1_to_mni_icbm1520GenericAffine.mat #affine output from last step
ms2mni_warp=ms_t1_to_mni_icbm1521Warp.nii.gz #warp from last step. There are a few, Warp, Warped Inver
seWarp, InverseWarped. I picked the one that matched my pnc output the closes

antsApplyTransforms -e 3 -d 3 -i ${mimosa_path} -o ${mimosa_mni_hcp_path} -r ${mni_hcp_path} -t ${ms2mni_warp} -t ${affine_mat} -n GenericLabel
```

20211013
  [x] made a copy of the pmacs stuff and put it locally for ease of making pictures
 [x] take the new lesion file, put it in dsi studio, and run the tractography to get the track loss. 
 [x] please please please git this
 [x] can also try to run with script from command line WORKS!
 [x] checked R/L orientation - cooking with gas

[x] there is a weird line in my pictures, so am going to try with different interpolation (Multilabel and Nearest Neighbor)
  - made new script: /project/msdepression/erica_created_for_hcp_reg/ants_transform_code.sh
  - to run:
  - ssh -Y eballer@scisub.pmacs.upenn.edu
  - module load ANTs/2.3.5
  - xbash
  - sh ants_transform_code.sh
  - if this doesn't work, type "export PATH=${ANTSPATH}:$PATH" at the command line
  
```{bash ants_transform_code.sh}
export PATH=${ANTSPATH}:$PATH
mimosa_path=mimosa_binary_mask_0.25.nii.gz #this is from mimosa output
mimosa_mni_hcp_path=mimosa_binary_mask_0.25_mni_hcp_gl.nii.gz #output file prefix
mni_hcp_path=mni_icbm152_t1_tal_nlin_asym_09axbrainmask.nii #template
affine_mat=ms_t1_to_mni_icbm1520GenericAffine.mat #affine output from last step
ms2mni_warp=ms_t1_to_mni_icbm1521Warp.nii.gz #warp from last step. There are a few, Warp, Warped Inver
seWarp, InverseWarped. I picked the one that matched my pnc output the closes

antsApplyTransforms -e 3 -d 3 -i ${mimosa_path} -o ${mimosa_mni_hcp_path} -r ${mni_hcp_path} -t ${ms2m
ni_warp} -t ${affine_mat} -n GenericLabel

mimosa_path=mimosa_binary_mask_0.25.nii.gz #this is from mimosa output
mimosa_mni_hcp_path=mimosa_binary_mask_0.25_mni_hcp_ml.nii.gz #output file prefix
mni_hcp_path=mni_icbm152_t1_tal_nlin_asym_09axbrainmask.nii #template
affine_mat=ms_t1_to_mni_icbm1520GenericAffine.mat #affine output from last step
ms2mni_warp=ms_t1_to_mni_icbm1521Warp.nii.gz #warp from last step. There are a few, Warp, Warped Inver
seWarp, InverseWarped. I picked the one that matched my pnc output the closes

antsApplyTransforms -e 3 -d 3 -i ${mimosa_path} -o ${mimosa_mni_hcp_path} -r ${mni_hcp_path} -t ${ms2m
ni_warp} -t ${affine_mat} -n MultiLabel

mimosa_path=mimosa_binary_mask_0.25.nii.gz #this is from mimosa output
mimosa_mni_hcp_path=mimosa_binary_mask_0.25_mni_hcp_nn.nii.gz #output file prefix
mni_hcp_path=mni_icbm152_t1_tal_nlin_asym_09axbrainmask.nii #template
affine_mat=ms_t1_to_mni_icbm1520GenericAffine.mat #affine output from last step
ms2mni_warp=ms_t1_to_mni_icbm1521Warp.nii.gz #warp from last step. There are a few, Warp, Warped Inver
seWarp, InverseWarped. I picked the one that matched my pnc output the closes

antsApplyTransforms -e 3 -d 3 -i ${mimosa_path} -o ${mimosa_mni_hcp_path} -r ${mni_hcp_path} -t ${ms2m
ni_warp} -t ${affine_mat} -n NearestNeighbor
```
  
  
  20211014
  
  [] Docker dsi studio
    - Tim downloaded 10/13
    
  [] Start making mimosa registrations for melissa's group
    - Melissa's QC'ed people 
  /project/pennsive_pacs2/repos/insurance/1yr_report_address.csv
  
  - first, filter the group to keep the people who have good mimosas (assumes that their T1s are also good, and pull out directory paths
  - make a file that contains people whose mimosas have quality 75, 100, and then combine
  
```{bash parse_mimosa_file.sh}

#n = 2336, corresponding to  958 subjects
more 1yr_report_address.csv | grep "mimosa" | grep ",,75.0" | perl -pe 's/(.*)\/mimosa.*/$1/' > mimosa_75_paths
more 1yr_report_address.csv | grep "mimosa" | grep ",,100.0" | perl -pe 's/(.*)\/mimosa.*/$1/' > mimosa_100_paths
cat mimosa_100_paths mimosa_75_paths > mimosa_100_and_75_paths
```
   New script for /project/msdepression/scripts/ants_registration_code.sh on pmacs. too nervous to git it
   
```{bash ants_registration_code.sh}


#read in directories
directories=$(cat $qc_file_path)

#extract name of directory and create shadow directory in my own data directory, with appropriate file names
for directory in $directories; do
        sub_sess_run=$(echo ${directory} | perl -pe 's/.*(sub.*)/$1/') #grab sub/sess/run
        echo $sub_sess_run
        echo "making dir" ${new_data_path}/${sub_sess_run}
        mkdir -p ${new_data_path}/${sub_sess_run}
        ln -s ${directory}/* ${new_data_path}/${sub_sess_run}
        cp ${mni_t1_path} ${new_data_path}/${sub_sess_run}

        #go into directory for afni stuff
        cd ${new_data_path}/${sub_sess_run}

        #make the dilated mask
        3dmask_tool -input ${brain_mask} -prefix ${brain_mask_dilated} -dilate_input ${mask_dilation}

        #multiply with mni t1 to get appropriate coverage
        3dcalc -a ${brain_mask_dilated} -b ${mni_t1_root}.nii -expr 'a*b' -prefix ${mni_t1_target}

        # a typical file 
#### Run registration

        antsRegistrationSyN.sh -d 3 -f ${mni_t1_target} -m ${t1} -o ${outfile_prefix} -x ${brain_mask_dilated}

        #now actually do the transform${brain
        mimosa_path=mimosa_binary_mask_0.25.nii.gz #this is from mimosa output
        mimosa_mni_hcp_path=mimosa_binary_mask_0.25_mni_hcp.nii.gz #output file prefix
        affine_mat=ms_t1_to_mni_icbm1520GenericAffine.mat #affine output from last step
        ms2mni_warp=ms_t1_to_mni_icbm1521Warp.nii.gz #warp from last step. There are a few, Warp, Warped InverseWarp, InverseWarped. I picked the one that matched my pnc output the closes

        antsApplyTransforms -e 3 -d 3 -i ${mimosa_path} -o ${mimosa_mni_hcp_path} -r ${mni_t1_target} -t ${ms2mni_warp} -t ${affine_mat} -n MultiLabel
        cd ${base_dir}
done

```
   
   20211015
   [x] Need to test ants registration code. If all goes well, hope to run this over the weekend
   [x]just need to add ants to my home directory somehow. But everything up to that seems to work
   
 
   
   Last update 20211015
   
   /project/msdepression/scripts/ants_registration_code.sh
```{bash ants_registration_code}

#!/bin/bash
### ANTS registration for MS Depression
##pre- requires ms mimosa file that contains the directory, mni brain: mni_icbm152_t1_tal_nlin_asym_09a.nii
##Post - ms participant T1w and mimosa registered to icbm_template space
##Uses - We have all of these great ms depression scans but they are in native space. This will get them into mni space so t
hey can be used with HCP templates, both structural and diffusion
#Steps
## 1 - take all file paths to data with good qc, extract file paths, and make shadow directories with linksin my local data 
directory
## 2 - make the dilated mask
     #####mask (currently using the one that was dilated in afni, d3
     ## 3dmask_tool -input t1_n4_brainmask.nii.gz -prefix t1_n4_brainmask_d3.nii.gz -dilate_input 3
## 3 - for each subject, run the registration, and then apply the transpforms
##Dependencies: Using ANTs/2.3.5
# Set up paths
module load ANTs/2.3.5
#export ANTSPATH="/appl/ANTs/2.3.5"
#export PATH=${ANTSPATH}:$PATH
export ANTSPATH=/appl/ANTs-2.3.5/bin

#######if it doesn't work, fix this ###
#export PATH=${ANTSPATH}:$PATH




#set default templatesfiles/paths

base_dir="/project/msdepression/scripts"

#Primary directorie - CHANGE THESE IF ANYTHING EVER CHANGES, IT WILL UPDATE FILE NAMES BELOW

qc_file_path='/project/msdepression/data/melissa_martin_files/csv/minimelissa_list_for_testing_n3'
mni_t1_root='mni_icbm152_t1_tal_nlin_asym_09a'
mask_dilation=3
brain_mask_root="t1_n4_brainmask"
t1="t1_n4_reg_brain_ws.nii.gz"
mimosa_root="mimosa_binary_mask_0.25"
new_data_path='/project/msdepression/data/subj_directories/'
mni_t1_direc="/project/msdepression/templates/mni_icbm152_nlin_asym_09a/"

#set outfile prefix
outfile_prefix=ms_t1_to_mni_icbm152

#for transform
mimosa_path=${mimosa_root}.nii.gz #this is from mimosa output
mimosa_mni_hcp_path=${mimosa_root}_mni_hcp.nii.gz #output file prefix
affine_mat=${outfile_prefix}0GenericAffine.mat #affine output from last step
ms2mni_warp=${outfile_prefix}1Warp.nii.gz #warp from last step. There are a few, Warp, Warped InverseWarp, InverseWarped. I 
picked the one that matched my pnc output the closes


#making some secondary files
mni_t1_path="${mni_t1_direc}/${mni_t1_root}.nii"
mni_t1_target="${mni_t1_root}xbrainmask.nii"
brain_mask="${brain_mask_root}.nii.gz"
brain_mask_dilated="${brain_mask_root}_d${mask_dilation}.nii.gz"

#read in directories
directories=$(cat $qc_file_path)

#extract name of directory and create shadow directory in my own data directory, with appropriate file names
for directory in $directories; do
        sub_sess_run=$(echo ${directory} | perl -pe 's/.*(sub.*)/$1/') #grab sub/sess/run
        echo $sub_sess_run
        echo "making dir" ${new_data_path}/${sub_sess_run}
        mkdir -p ${new_data_path}/${sub_sess_run}
        ln -s ${directory}/* ${new_data_path}/${sub_sess_run}
        cp ${mni_t1_direc}/${mni_t1_root}* ${new_data_path}/${sub_sess_run}

        #go into directory for afni stuff
        cd ${new_data_path}/${sub_sess_run}

        	#make the dilated mask
        	3dmask_tool -input ${brain_mask} -prefix ${brain_mask_dilated} -dilate_input ${mask_dilation}

        	#multiply with mni t1 to get appropriate coverage - this is the problem!!! 
        	3dcalc -a ${mni_t1_root}.nii -b ${mni_t1_root}_mask.nii -expr 'a*b' -prefix ${mni_t1_target}

         
		#### Run registration

        	antsRegistrationSyN.sh -d 3 -f ${mni_t1_target} -m ${t1} -o ${outfile_prefix} -x ${brain_mask_dilated}

        	#now actually do the transform${brain
       
       	 	antsApplyTransforms -e 3 -d 3 -i ${mimosa_path} -o ${mimosa_mni_hcp_path} -r ${mni_t1_target} -t ${ms2mni_wa
rp} -t ${affine_mat} -n GenericLabel
        
	cd ${base_dir}
done

```

20211019
Still having issues with transform, running slow, realizing that I had multilable instead of generic label. Will try that. Still worried I will have trouble getting it to work.

Got it to run by putting a bsub inside the script!

20211026
- Now trying to get dsi studio to run on pmacs. 
- scp -r /Users/eballer/msdepression/templates/dti to /project/msdepression/templates

Made a list of the paths to all the mimosa masks
ls /project/msdepression/data/subj_directories/*/*//*/mimosa*mn* > mimosa_binary_masks_hcp_space_20211026_n2336

Then moved to melissa's data directory
cp mimosa_binary_masks_hcp_space_20211026_n2336 ../melissa_martin_files/csv/.

20211027
 - fixing dsi studio. Goal today is to figure out how to bsub it because it takes a long time. steps
 
```{bash}
ssh -Y eballer@scisub.pmacs.upenn.edu
cd /project/msdepression/scripts
xbash

```
 
 
 Also needed to generate a list of niftis (i.e. tracts is voxel space). Did this locally and scp'ed to templates/dti
 
```{bash}
#!/bin/bash

#### Welcome to the Region_making party #########
### Pre: Must have a file with full paths to the lesioned data 
### Post: Within each directory specified by the lesioned data, will have a directory that has all tractography (ROA, ROI, Full)
### Uses: For use in MS depression - take a subject's mimosa lesions and generate the fiber tracts (individual fascicles) that run through it
#dependencies: Using dsi studio downloaded 9/2021

export PATH=${PATH}:/Applications/dsi_studio.app/Contents/MacOS/
template='/Users/eballer/BBL/msdepression/templates/dti/HCP1065.1mm.fib.gz'
default='/Users/eballer/BBL/msdepression/data/mimosa_file_paths'
fascicle_directory='/Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography/'

if [ $# == 0 ]
then
    echo "We will use the default mimosa path file" $default
    lesion_file=$default
else  
    lesion_file=$1
fi
echo "File being read is "$lesion_file
echo "... Starting to make lesions ..."

lesion_paths=$(cat $lesion_file)

for lesion in ${lesion_paths}; do
    echo "Working on file" $lesion
    # make directory within parent directory for tracts
    #parent_dir=$(echo $lesion | perl -pe s'/(.*)\/.*/$1/g')
    mask_prefix=$(echo $lesion | perl -pe s'/(.*)\/(.*).nii.gz/$2/g')
    if [ ! -d $parent_dir/fiber_tracking_maps ] 
    then
        mkdir $parent_dir/fiber_tracking_maps
    fi

    fiber_bundle_type_list=(
        "association"
        "cerebellum"
        "cranial_nerve"
        "projection"
        "commissural")
    for fiber_bundle_type in "${fiber_bundle_type_list[@]}"; do
        echo "Fiber bundle type is " $fiber_bundle_type
        echo "making directory" $parent_dir/fiber_tracking_maps/$fiber_bundle_type
        #mkdir $parent_dir/fiber_tracking_maps/$fiber_bundle_type
        fascicles=$(ls ${fascicle_directory}/${fiber_bundle_type}/*.tt.gz)
        for fascicle in ${fascicles}; do
            echo "Fascicle is  " $fascicle
            fascicle_root_name=$(echo $fascicle | perl -pe s'/(.*)\/(.*).tt.gz/$2/g') 
          #  dsi_studio --action=ana --source=$template --tract=$fascicle --roa=$lesion --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_lesioned_ROA.tt.gz
          #  dsi_studio --action=ana --source=$template --tract=$fascicle --roi=$lesion --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_lesioned_ROI.tt.gz
           # dsi_studio --action=ana --source=$template --tract=$fascicle --output=${fascicle_directory}/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_full.tt.gz
            dsi_studio --action=ana --source=$template --tract=$fascicle --output=${fascicle_directory}/${fiber_bundle_type}/${fascicle_root_name}.nii.gz
        done
        # $path/dsi_studio --action=ana --source=/Users/eballer/BBL/msdepression/templates/dti/HCP1065.1mm.fib.gz --tract=/Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography/association/SLF2_R.tt.gz --roa=/Users/eballer/BBL/msdepression/templates/perfect_ms_subject/run-001/mimosa_binary_mask_0.25.nii.gz --output=/Users/eballer/BBL/msdepression/templates/roi_files_for_testing/SLF2R_lesioned_ROA.nii.gz
        # $path/dsi_studio --action=ana --source=/Users/eballer/BBL/msdepression/templates/dti/HCP1065.1mm.fib.gz --tract=/Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography/association/SLF2_R.tt.gz --roi=/Users/eballer/BBL/msdepression/templates/perfect_ms_subject/run-001/mimosa_binary_mask_0.25.nii.gz --output=/Users/eballer/BBL/msdepression/templates/roi_files_for_testing/SLF2R_lesioned_ROI.nii.gz
        # $path/dsi_studio --action=ana --source=/Users/eballer/BBL/msdepression/templates/dti/HCP1065.1mm.fib.gz --tract=/Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography/association/SLF2_R.tt.gz --output=/Users/eballer/BBL/msdepression/templates/roi_files_for_testing/SLF2R_full_ROI.nii.gz
    done
done
```
 20211028 
 
 Big moves! Currently running these two scripts and they have been git'ed
```{bash dsi_studio_bash.sh}
#!/bin/bash

#### Welcome to the Region_making party #########
### Pre: Must have a file with full paths to the lesioned data 
### Post: Within each directory specified by the lesioned data, will have a directory that has all tractography (ROA, ROI, Full)
### Uses: For use in MS depression - take a subject's mimosa lesions and generate the fiber tracts (individual fascicles) that run through it
#dependencies: Using dsi studio from docker, sif created by Tim 10/26/2021
#export PATH=${PATH}:/Applications/dsi_studio.app/Contents/MacOS/
set -euf -o pipefail

export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=$LSB_DJOB_NUMPROC
num_cores=1

#set default paths 
template='/project/msdepression/templates/dti/HCP1065.1mm.fib.gz'
default='/project/msdepression/data/melissa_martin_files/csv/mimosa_binary_masks_hcp_space_20211026_n2336'
#default='/project/msdepression/data/melissa_martin_files/csv/erica_mini_mimosa_paths_n3'
fascicle_directory='/project/msdepression/templates/dti/HCP_YA1065_tractography/'

if [ $# == 0 ]
then
    echo "We will use the default mimosa path file" $default
    lesion_file=$default
else  
    lesion_file=$1
fi
echo "File being read is "$lesion_file
echo "... Starting to make lesions ..."

lesion_paths=$(cat $lesion_file)

# loop through each mimosa lesion map; lesion paths contain full paths to mimosa files in hcp space
job_count=1
for lesion in ${lesion_paths}; do
	echo "working on ${lesion} ..."  
	bsub -J "job_${job_count}" -n ${num_cores} -o /project/msdepression/scripts/logfiles/out_roa_${job_count}.out /project/msdepression/scripts/indiv_mimosa_lesion_dsi_s
tudio_script.sh $lesion
   	((job_count+=1))
done

```
 
and this calls 
```{bash indiv_mimosa_lesion_dsi_studio_script.sh}

### The Inner Script... Doing all the dsi studio action for each individual mimosa brain ###

### Pre: path to an individual's mimosa lesion in HCP/MNI space
### Post: Filtered tracts; ROA and ROI voxel maps/niftis that can be used for data analysis
### Uses: In trying to find a way to speed everything along, it made the most sense to separate this piece of the script out. 
#          - it takes a subject's mimosa path, and makes a fiber_tracking_map directory as well as sub directories for each bundle type
#          - it then runs ROA/ROI filtration and makes output maps. 

#set -euf -o pipefail
module load singularity
export PATH=${PATH}:/Applications/dsi_studio.app/Contents/MacOS/
export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=$LSB_DJOB_NUMPROC
num_cores=1

#set default directory/templates. This will change when we use local, personal dwi
template='/project/msdepression/templates/dti/HCP1065.1mm.fib.gz'
fascicle_directory='/project/msdepression/templates/dti/HCP_YA1065_tractography/'

if [ $# == 0 ]
then
    echo "You did not enter a file. Make sure your call makes sense"
else  
    lesion=$1

	echo "File being read is "$lesion
	echo "... Starting to make tracts"
# make directory within parent directory for tracts
    	parent_dir=$(echo ${lesion} | perl -pe s'/(.*)\/.*/$1/g')
    	echo "$parent_dir"
	mask_prefix=$(echo ${lesion} | perl -pe s'/(.*)\/(.*).nii.gz/$2/g')
    	echo $mask_prefix
	if [ ! -d $parent_dir/fiber_tracking_maps ] 
    	then
        	mkdir $parent_dir/fiber_tracking_maps
    	fi

    #make sub directories for each bundle type, so within fiber_tracking_maps, there will be subdirectories for each type of map
	fiber_bundle_type_list="association cerebellum cranial_nerve projection commissural"	
    	for fiber_bundle_type in ${fiber_bundle_type_list}; do
        	echo "Fiber bundle type is " $fiber_bundle_type
        	echo "making directory" $parent_dir/fiber_tracking_maps/$fiber_bundle_type
        	mkdir $parent_dir/fiber_tracking_maps/$fiber_bundle_type
        	fascicles=$(ls ${fascicle_directory}/${fiber_bundle_type}/*.tt.gz)
    

	# set a job counter to be used to name the jobs
		job_count=1
		for fascicle in ${fascicles}; do
            		echo "Fascicle is  " $fascicle
            		fascicle_root_name=$(echo $fascicle | perl -pe s'/(.*)\/(.*).tt.gz/$2/g') 
   			echo  "Fascicle root name is ${fascicle_root_name}" 
    	    		singularity exec --bind /project /project/singularity_images/dsistudio_latest.sif dsi_studio --action=ana --source=$template --tract=$fascicle --roa=
$lesion --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_lesioned_ROA.tt.gz
            		singularity exec --bind /project /project/singularity_images/dsistudio_latest.sif dsi_studio --action=ana --source=$template --tract=$fascicle --roi=
$lesion --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_lesioned_ROI.tt.gz
           
     			singularity exec --bind /project /project/singularity_images/dsistudio_latest.sif dsi_studio --action=ana --source=$template --tract=$fascicle --roa=
$lesion --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_lesioned_ROA.nii.gz
           		singularity exec --bind /project /project/singularity_images/dsistudio_latest.sif dsi_studio --action=ana --source=$template --tract=$fascicle --roi=
$lesion --output=$parent_dir/fiber_tracking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_lesioned_ROI.nii.gz
 
		# I have removed this line to save space. All hcp fibers are in the directory: /project/msdepression/templates/dti/HCP_YA1065_tractography/ . Can uncomment t
his if at some point I need to make them for each individual, like when we have their personal DWI
#singularity exec --bind /project /project/singularity_images/dsistudio_latest.sif dsi_studio --action=ana --source=$template --tract=$fascicle --output=$parent_dir/fiber_tr
acking_maps/${fiber_bundle_type}/${fascicle_root_name}_${mask_prefix}_full.tt.gz
			((job_count+=1))
		done
    	done
fi
```

20211029
[x] 3dmaskave, get the # of voxels into csvs

scripts are made, just have no more space on pmacs, so waiting for them to make space for me and then I can do this.

20211103
[x] start working on getting these files into r, MAKE SURE TO ADD A ZERO in the read in line = NA -> 0!!!

20211104
[x] ton of weird errors that are inconsistent with afni. Need to figure out if they are real or fake.

Here is how I figured out the failed subj/session #
```{bash}
more 3dmaskav_*.out | grep "ERROR" | perl -pe 's/.*\/project.*\/(sub-.*\/ses-.*)\/run.*/$1/' | sort -u > failed_3dmaskave_n243_20211103
```

Have identified the people who failed, it looks like their lesions are empty for these
```{bash}
more failed_3dmaskave_n243_20211103 | perl -pe 's/(.*)/\/project\/msdepression\/data\/subj_directories\/$1\/run-001\/mimosa_binary_mask_0.25_mni_hcp.nii.gz/' > failed_full_mimosa_paths_n243
```

[x]Going to try rerunning these specifically from the dsi_studio command, using these files instead of what is already there

Have to make a file that contains all the full volumes of each of the fascicles

```{bash make_streamline_volumes_for_template.sh}
### Make streamline volumes ###

### Pre: All template streamlines must have been made in dsi studio (these are the nii files)
### Post: fiber_volume_values.csv that contains the name of the fiber bundle and its volume
### Uses: Will be getting the volumes of the streamlines for use in later density analyses
### Dependencies: This script requires afni to be installed.

module load afni_openmp/20.1
export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=$LSB_DJOB_NUMPROC
num_cores=1

directory='/project/msdepression/templates/dti/HCP_YA1065_tractography/'
outfile=${directory}/fiber_volume_values.csv

#remove outfile if it exists
rm -f ${outfile}

#make the file again
touch ${outfile}
echo "fascicle,volume" >> ${outfile}
   
#go through each fiber, get volume, and store it in csv
fiber_bundle_type_list="association cerebellum cranial_nerve projection commissural"	
for fiber_bundle_type in ${fiber_bundle_type_list}; do
	echo "Fiber bundle type is " $fiber_bundle_type
fascicle_volumes=$(ls ${directory}/${fiber_bundle_type}/*.nii*)
        for fascicle in ${fascicle_volumes}; do
            fascicle_prefix=$(echo $fascicle | perl -pe 's/.*\/(.*).nii.*/$1/g')
            volume=$(3dmaskave -quiet -mask SELF -sum ${fascicle})
            echo "${fascicle_prefix},$volume" >> ${outfile}
        done
done
```


output of the above script
```{bash}
fascicle,volume
AF_L,35716
AF_R,15249
C_FPH_L,2569
C_FPH_R,2760
C_FP_L,14457
C_FP_R,21386
C_PH_L,3171
C_PHP_L,1900
C_PHP_R,4612
C_PH_R,2593
C_R_L,2666
C_R_R,5181
EMC_L,7344
EMC_R,5641
FAT_L,27142
FAT_R,15510
IFOF_L,30311
IFOF_R,34880
ILF_L,27401
ILF_R,36327
MdLF_L,7637
MdLF_R,5744
PAT_L,10921
PAT_R,13976
SLF1_L,9836
SLF1_R,13482
SLF2_L,26947
SLF2_R,37091
SLF3_L,10053
SLF3_R,15526
UF_L,7607
UF_R,7744
VOF_L,5681
VOF_R,4079
CB_L,45470
CB_R,43251
ICP_L,4963
ICP_R,4449
MCP,16514
SCP,4315
V,11299
CNIII_L,563
CNIII_R,486
CNII_L,1097
CNII_R,1415
CNVIII_L,1034
CNVIII_R,968
CNVII_L,298
CNVII_R,276
CNV_L,817
CNV_R,995
AR_L,3082
AR_R,1935
CBT_L,4609
CBT_R,6146
CPT_F_L,18693
CPT_F_R,34955
CPT_O_L,9022
CPT_O_R,7015
CPT_P_L,24377
CPT_P_R,27829
CS_A_L,26114
CS_A_R,21542
CS_P_L,5526
CS_P_R,6231
CS_S_L,31034
CS_S_R,34141
CST_L,20476
CST_R,16388
DRTT_L,14986
DRTT_R,17163
F_L,5175
F_R,8018
ML_L,10871
ML_R,9139
OR_L,6876
OR_R,5510
RST_L,14766
RST_R,11890
TR_A_L,20628
TR_A_R,14840
TR_P_L,4402
TR_P_R,4748
TR_S_L,39767
TR_S_R,37036
AC,26517
CC,390601
```

2021104
[x] need to see if total number of fibers in a bundle = ROA + ROI - NO
[] if all these work, our first analyses will be depressed vs non total , total fiber volume lost in lesions, then specificity. WOuld look at ratios ROI/total

To initialize Rstudio on pmacs
```{bash}
source  /project/bbl_projects/apps/default_modules.sh
conda activate rstudio
xbash
rstudio
### OR ###
cd /project/msdepression/scripts
source load_rstudio
```

To make list of all roi files
```{bash}
cd /project/msdepression/data/melissa_martin_files/csv/
more mimosa_binary_masks_hcp_space_20211026_n2336 | perl -pe 's/(.*)mimosa_bin.*/$1fiber_tracking_maps\/fiber_volume_values_roi\.csv/' > roi_fiber_volumes_n2336
```

Rscript to make df with lesions

```{r Roi_ratio_regressions}
### ROA Ratio Regressions ###

#####
## Pre: /project/msdepression/data/melissa_martin_files/csv/roi_fiber_volumes_n2336, which contains full paths to the ROI files, can be ammended to do ro
## Post: Analysis
## Uses: 1) reads in the ROIs, puts them in a data frame (columns are accession num/date/each fascicle), one row per subjected per date
#        2) Performers univariate analyses, depression diagnosis versus not
## Dependencies: R 3.6.3

#include packages
library(dbplyr)

#set directories
homedir<-'/project/msdepression/'

#analysis type
region_type="roi"

#read in template fascicle volumes
template_full_volumes <- read.csv(paste0(homedir, '/templates/dti/HCP_YA1065_tractography/fiber_volume_values.csv'), header = T)
fascicle_names <- template_full_volumes$fascicle

### Read in file with all full paths to region volumes
region_volume_csv <- read.table(paste0(homedir, '/data/melissa_martin_files/csv/', region_type, '_fiber_volumes_n2336'), header = F, stringsAsFactors = F)
region_volume_csv$V1 <- as.character(region_volume_csv$V1)

#outfile, named for number of subjects
outfile <- paste0(homedir, "/results/fascicle_volumes_all_subjects_", region_type, "_n", dim(region_volume_csv)[1], ".csv")

#make data frame, 1 row per subject, num rows = num rows in region_volume_csv
volumes_df <- data.frame(matrix(nrow = dim(region_volume_csv)[1], ncol = 89))
names(volumes_df) <- c("ACCESSION_NUM", "EXAM_DATE", as.character(fascicle_names))
#loop through region_volume_csv, read in df corresponding to each row of region_volume_csv, extract accession num and date,
## and transpose fiber volumes from column to rows. append accession num/date/region_volumes row into big matrix

for (subj in 1:dim(region_volume_csv)[1]) {
  file_path <- region_volume_csv$V1[subj]
  region_volume_data <- read.csv(file_path, header = T, sep = ",")
  accession_num<- region_volume_data[1,1]
  date <- region_volume_data[1,2]
  volumes <- t(region_volume_data[,4])
  volumes[is.na(volumes)] <- 0
  volumes <- volumes/template_full_volumes$volume
  row_to_add <- cbind(accession_num, date, volumes)
  volumes_df[subj,]<- row_to_add
}

write.csv(file=outfile, volumes_df, quote = FALSE, row.names = FALSE)



```


To see the frequencies of the lesions
```{bash MC plot}
library(reshape2)
library(ggplot2)
df <- read.csv("fascicle_volumes_all_subjects_roi_n2336.csv", header=TRUE)

m.df <- melt(df, id.vars = c("ACCESSION_NUM", "EXAM_DATE"))
lesioned <- subset(m.df, value > 0)

ggplot(lesioned, aes(x=value)) + geom_histogram() + facet_wrap(~variable)
```



20211107
[x] need to divide the ROIs by the total volume 

20211109
[x] need to change the date format in my regular dac pull
 - pulled the results down to my local machine
```{bash}
scp eballer@transfer.pmacs.upenn.edu:/project/msdepression/results/fascicle_volumes_all_subjects_roi_n2336.csv .
```
 [x] age
 [x] sex
 [x] depression
 [x] repeated measures
 [x] exclusions flow chart
   - compare # good phq2s/9s in the direction of depression
 [x] meeting with matt taki setup
 
 20211117
  making a list of my people with depressed/not depressed with melissa rating
```{bash}
#done locally on /Users/eballer/BBL/msdepression/data/dac
more 1yr_report_address.csv | grep "mimosa" | perl -pe 's/.*sub-(.*)\/ses-(.*)\/run.*gz,.*,(.*),20.*/$1,$2,$3/' > just_empi_date_rating

# to count how many people are unique in our gorup of people with qc, n = 1059
 more 1yr_report_address.csv | grep "mimosa" | perl -pe 's/.*sub-(.*)\/ses-(.*)\/run.*gz,.*,(.*),20.*\/pro.*/$1,$2,$3/' | cut -f 1 -d ',' | sort -u | wc


```
 
 20211118
 - my dac summary thing is getting too meaty and I can't find anything anymore. Making a new rmd with analyses.
 [x] msdepression_regressions_started_20211118.Rmd
 
20211123
[] make regression function

[] need to get total # of lesions - this will be tough, need taki's code. Not to do right now - sydney to look into

20211201
[x] trying to figure out why some people completely bottom out with their lesions. Looks like some fail registration, though I'm not really sure why.
[] make depression mask

plan to calculate depression network overlap:

1) take the depression network map and 3dresample it into the voxel space of any of the fascicle masks
2) for each fascicle mask, multiply the mask by the resampled depression network. then count the nonzero voxels. The number of nonzero voxels is the volume overlap of that fascicle with the depression network
3) plot the histogram of depression network overlap volumes. Hopefully there will be a notch in it where we can say anything beneath X mm^3 is not connected to the depression network

on local machine, make binary mask
```{bash}
cd /Users/eballer/BBL/msdepression/templates/harvard_depression
3dcalc -a Depression_Clust_mask_rois.nii.gz -expr 'ispositive(a)' -prefix Depression_Clust_mask_roi_binarized.nii.gz
scp -r harvard_depression eballer@transfer.pmacs.upenn.edu:/project/msdepression/templates/.
```

On cluster
```{bash}
cd /project/msdepression/templates/harvard_depression
3dresample -master AF_L.nii.gz -prefix "resampled_hcp_space_harvard_dep_mask.nii.gz" -input Depression_Clust_mask_roi_binarized.nii.gz
```

code for calc_vol_fascicles_within_depression_mask.sh 
```{bash calc_vol_fascicles_within_depression_mask}
#### calculate volume of fascicles within the depression network ####
### Pre: All streamlines must have been made in dsi studio (these are the nii files)
### Post: A depression mask resampled to template space, file <streamline_volume_within_dep_network>, containing each fascicle and its corresponding % within depression netw
ork
### Uses: Trying to figure out which fascicles are in the depression network for dimensionality reduction for use in later regressions (i.e. decrease # comparisons by only l
ooking at fascicles within depression network)
### Dependencies: This script requires afni to be installed (currently using 20.1)

#set outfile
outfile="/project/msdepression/results/streamline_volume_within_dep_network.csv"

#set template directories, will be making our resampled mask from within this
template="Depression_Clust_mask_roi_binarized.nii.gz"
template_dir="/project/msdepression/templates/harvard_depression"
resampled_filename="resampled_${template}"
template_fullpath="/project/msdepression/templates/harvard_depression/${template}"

#set fascicle directory
fascicle_direc="/project/msdepression/templates/dti/HCP_YA1065_tractography/"
fascicle_type="association"
fascicle_for_resampling="AF_L.nii.gz"

#set home directory
homedir="/project/msdepression/scripts/"

#initiate csvs
rm -f $outfile
touch $outfile
echo "fascicle,num_voxels_total,non_zero_voxels_in_dep_map,prop_in_mask" >> $outfile

#resample Depression_Clust_amsk_roi_binarized.nii.gz to match sample fascicle - AF_L.nii.gz
if [ -f "${template_dir}/${resampled_filename}" ]; then
	rm -f ${template_dir}/${resampled_filename}
fi
3dresample -master ${fascicle_direc}/${fascicle_type}/${fascicle_for_resampling} -prefix ${template_dir}/${resampled_filename} -input ${template_fullpath} -rmode NN

#go through each fiber, get volume, and store it in csv
fiber_bundle_type_list="association cerebellum cranial_nerve projection commissural"
for fiber_bundle_type in ${fiber_bundle_type_list}; do
    echo "Fiber bundle type is " $fiber_bundle_type
    fascicle_volumes=$(ls ${fascicle_direc}/${fiber_bundle_type}/*.nii* | grep -v "dep_mask") #list all files, exclude depression ones
    for fascicle in ${fascicle_volumes}; do
	    fascicle_prefix=$(echo $fascicle | perl -pe 's/.*\/(.*).nii.gz/$1/g')
	    num_voxels_whole_mask=$(3dmaskave -quiet -mask SELF -sum ${fascicle})

	    #remove previous mask if already made
	    if [ -f "${fascicle_direc}/${fascicle_type}/${fascicle_prefix}xdep_mask.nii.gz" ]; then
		    rm -f ${fascicle_direc}/${fascicle_type}/${fascicle_prefix}xdep_mask.nii.gz
	    fi

	    3dcalc -a ${template_dir}/${resampled_filename} -b ${fascicle} -expr 'a*b' -prefix ${fascicle_direc}/${fascicle_type}/${fascicle_prefix}xdep_mask.nii.gz
	    num_nonzero_volumes=$(3dmaskave -quiet -mask SELF -sum ${fascicle_direc}/${fascicle_type}/${fascicle_prefix}xdep_mask.nii.gz)
	    prop_in_mask=$(echo ${num_nonzero_volumes}/${num_voxels_whole_mask} | bc -l)
	    echo "num_voxels" $num_voxels_whole_mask "num_nonzero" $num_nonzero "prop_in_mask" $prop_in_mask

	    echo "${fascicle_prefix},${num_voxels_whole_mask},${num_nonzero_volumes},${prop_in_mask}" >> $outfile
    done
done
```


Moved back to home directory
```{bash}
#from local machine
scp eballer@transfer.pmacs.upenn.edu:/project/msdepression/results/streamline_volume_within_dep_network.csv .

#moved 
```

get volume in dep network per fascicle

#### 20211203
So something cool is happening here, but unexpected. The areas in the brain that have the most significant disease are much more likely to be in the depression network versus outside of it. p<1*10^-15. Doesn't matter whether or not you are depressed, they seem to share the same network. Also, areas that tend to worsen with age also are more likely to be in the same network. Will be interesting to figure out why some people don't get depressed, if people all have disease there. Also, why is there overlap? Interesting that inflammatory attack of WM happens to be in the depression network - is this why inflammation makes depression? Is there something structurally that happens along these white matter tracts? Weaker BBB? Different energetic characteristics? Is the same inflammation/depression network overlap seen in other inflammatory white matter diseases with a high burden of depression, or just MS? Will higher numbers allow the individual fascicle difference prediction to come up? Or is this really just a case where HYDRA will identify subtypes (which I imagine might be the case)
20211202
[] figure out why registration broke - not sure

#### 20220621
Such a long lag! Back to now trying to figure out how to do spin tests with ms data. This was raised to address the observation that people, overall, are more likely to have disease in the depression network, but the depression network is so big that we want to see how specific this finding it. Thus the spin test.

Currently, the idea is as follows:

Surface to volume -> spinning -> volume to surface: 

[x] 1) Take depression voxel mask Depression_Clust_mask_roi_binarized.nii.gz (done locally, /Users/eballer/BBL/msdepression/templates/harvard_depression)

    - of note, Depression_Clust_mask_roi_binarized.nii.gz was generated from a mask made by Matt (Depression_Clust_mask_rois.nii.gz)
    - command from 3dinfo: 3dclust -1Dformat -nosum -1dindex 0 -1tindex 0 -1noneg -2thresh -0.1317 0.1317 -dxyz=1 -savemask Clust_mask 1.01 20 /Users/mcieslak/Desktop/AllFX_wmean.nii
    
```{bash}
3dcalc -a Depression_Clust_mask_roi_binarized.nii.gz -expr 'ispositive(a)*ispositive(x)' -prefix Depression_Clust_mask_roi_binarized_l.nii
3dcalc -a Depression_Clust_mask_roi_binarized.nii.gz -expr 'ispositive(a)*isnegative(x)' -prefix Depression_Clust_mask_roi_binarized_r.nii
```
    
    - output: L & R hemisphere volume images
        - Depression_Clust_mask_roi_binarized_l.nii
        - Depression_Clust_mask_roi_binarized_r.nii
          
[] 2) Project to vertex space using vol2surf from imco, fs5 space

```{bash}
scp Depression_Clust_mask_roi_binarized_*.nii eballer@transfer.pmacs.upenn.edu:/project/msdepression/templates/harvard_depression/.
cp /project/imco/from_chead/coupling_test_eb_20200918/code/vol2surf* /project/msdepression/scripts/. 
cp /project/imco/from_chead/coupling_test_eb_20200918/code/transformMatrix.R /project/msdepression/scripts/.
```
    - need to register the volume to some template (hcp) and use that I think
OLD
```{bash}
lta_convert --infsl ${boldDir}/${bblid}_${datexscanid}_seq2struct.mat \
	--outreg ${targDir}/${bblid}/${datexscanid}/${bblid}_${datexscanid}_seq2struct.dat \
	--subject ${bblid}/${datexscanid} \
	--src ${boldDir}/${bblid}_${datexscanid}_referenceVolume.nii.gz \
	--trg ${boldDir}/${bblid}_${datexscanid}_targetVolume.nii.gz \
	>> ${targDir}/${bblid}/${datexscanid}/${bblid}_${datexscanid}_projection.log 2>&1
```

NEW (believe I use diff flags), think about using ants_registration_code.sh on pmacs
```{bash}
lta_convert --infsl ${boldDir}/${bblid}_${datexscanid}_seq2struct.mat \
	--outreg ${targDir}/${bblid}/${datexscanid}/${bblid}_${datexscanid}_seq2struct.dat \
	--subject ${bblid}/${datexscanid} \
	--src ${boldDir}/${bblid}_${datexscanid}_referenceVolume.nii.gz \
	--trg ${boldDir}/${bblid}_${datexscanid}_targetVolume.nii.gz \
	>> ${targDir}/${bblid}/${datexscanid}/${bblid}_${datexscanid}_projection.log 2>&1
```

    - output: L & R hemisphere vertex images, all binarized
[] 3) Spin 1000 times per hemisphere
    - output 1000 L & R hemisphere surfaces
[] 4) Surface back to voxel
    - output 1000 L & R hemisphere volumes
[] 5) Merge L & R volumes together
    - output 1000 spun depression network volumes

[] 6) Calculate volume of fascicles within each spun depression mask  
    - have to wrap script: calc_vol_fascicles_within_dep_mask.sh, which outputs a spreadsheet with last column being proportion of each of 87 fascicles within depression mask
    - output table (column is proportion of fascicle in dep network, row is fascicle:
                 Spin 1 prop   Spin 2 prop   Spin 3 prop   Spin 4 prop ... Spin 1000 prop
    Fascicle 1    0.21
    Fascicle 2    0
    Fascicle 3    0.33
    Fascicle 4    0.1
    ...
    Fascicle 87   0
    
[] 7) Take above spreadsheet, make binarized
    - Will assume that if the fascicle has ANY overlap depression network, ie spin prop > 0, will be in dep net
    - output table (column is proportion of fascicle in dep network, row is fascicle:
 
                 Spin 1 prop   Spin 2 prop   Spin 3 prop   Spin 4 prop ... Spin 1000 prop
    Fascicle 1    1
    Fascicle 2    0
    Fascicle 3    1
    Fascicle 4    1
    ...
    Fascicle 87   0
    
[] 8) Enrichment/calculations
    - Now, for each spin, will be calculating the dep vs nondep enrichment.
    - Two ways to do this
        1) Means (i.e calculate mean of depression overlap[proportion] in real data and each spin, and mean of non-dep overlap)
          - output
          
                                 Spin 1    Spin 2    Spin 3    Spin 4 ... Spin 1000
          Dep Mean % overlap
          Nondep Mean % overlap
          
        2) T tests - two sample T at each spin
          - output
                                Spin 1    Spin 2    Spin 3    Spin 4 ... Spin 1000
          Dep vs nondep T       3.2       1.2       4.5       1.1
          
[] 9) Sort, calculate top 5%
    a) Means: Do separately for depression and non-depression/kinda like an enrichment
    b) Ts: Just do 1 time, sort 
    
    Will try both, put Ts first as more straightforward

-----------
#### 20220622 
Put a hold on surface projections above as I need people to come back from HBM. Instead, working on descriptives for potential paper 1

Rmarkdown: /Users/eballer/BBL/msdepression/scripts/Descriptive_potential_paper_1_20220622.Rmd

Redid overall tracts, age, sex, agexsex unique/mixed models.

#### 20220623
Downloaded Yeo volume masks: https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation_Yeo2011

Separated out each functional network
```{bash afni_commands_to_construct_yeo_indiv_vol_masks.sh}
#!/bin/sh

# pre: Yeo cortical parcellations (7 network) in volumetric space: https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation_Yeo2011
# post: 7 individual network maps: VIS, MOT, DA, VA, LIM, FP, DM, labeled yeo_7_vol_[network abbreviation]
# uses: This script takes the parcellations in volume (Yeo2011_7Networks_MNI152_FreeSurferConformed1mm_LiberalMask.nii) and makes 7 individual maps. In the Yeo2011 volume mask, each network is given a number (1-7), with 1 corresponding to VIS, and 7 corresponding to DM. In order to make individual maps, I need to separate out each network in the map based on intensity. Will try to code in the following way: 1) make a vector where each item is the name of the network 2) make a loop that counts the networks 3) go through each network and do math to pull out only the network with a particular intensity. It uses the command "amongst", which gives back the voxels where the intensity is equivalent to the counter, multiplies it times the whole mask (so now every voxel contains the intensity of interest, everything else is 0), and then binarizes. 
# dependencies: Afni 

#make list of yeo network abbreviations
yeo_7_net_list=("VIS"
                "MOT"
                "DA"
                "VA"
                "LIM"
                "FP"
                "DM")

#network path
network_path=/Users/eballer/BBL/msdepression/templates/Yeo_JNeurophysiol11_MNI152/

#current working directory
cwd=`pwd`
echo $cwd

#set volume mask [change this if I ever want to use a diff mask
volume_mask=Yeo2011_7Networks_MNI152_FreeSurferConformed1mm_LiberalMask.nii

#assign generic network_prefix_list variable; this is in case I decide I want to do this for 17 networks
network_prefix=yeo_7_net
network_list=$(echo ${network_prefix}_list)

echo "network list = ${network_list}"

#set counter, this will be used in loop
network_counter=1

echo "Volume mask = ${volume_mask}"

echo "Deleting old masks"
rm -f ${network_path}/${network_prefix}_*.nii

echo "Making individual network maps"
#for loop; goes through each network, pulls out the mask that corresponds to that network number, and stores it with the appropriate prefix

#have to write out yeo_7_net_list because bash can't handle too many extractions. Prob because I'm not referencing an object but a name when pointing network list to yeo_7_net_list
for network in "${yeo_7_net_list[@]}"; do
        echo "making ${network} mask, counter = ${network_counter}"
        
#make binary masks of each level of the masks; amongst just takes only the values given in the next segment, which can be 1 or more
        afni_command=("3dcalc -a ${network_path}/${volume_mask} -expr 'ispositive(a*amongst(a,${network_counter}))' -prefix ${network_path}/${network_prefix}_${network}.nii")
        echo $afni_command
        eval $afni_command
        ((network_counter++))
done

#go back to current working directory
#cd $cwd
```

#### 20220624
[x] Move masks from local to pmacs, log onto pmacs, etc
```{bash}
scp yeo_7_net_* eballer@transfer.pmacs.upenn.edu:/project/msdepression/templates/Yeo_JNeurophysiol11_MNI152/.
ssh -Y eballer@scisub.pmacs.upenn.edu
cd /project/msdepression/scripts
xbash
module load afni[tab complete]
```

[x] Map each of the fascicles to the corresponding functional network (i.e. use as ROI like I did with depression)
[x] make list of which fascicles go in which network
```{bash calc_vol_fascicles_within_yeo_7_net.sh}
#### calculate volume of fascicles within the yeo 7 networks ####
### Pre: All streamlines must have been made in dsi studio (these are the nii files)
### Post: Yeo7 network mask resampled to template space, file <streamline_volume_within_${network}_network>, containing each fascicle and its corresponding % within yeo network. Additionally, will have a file that contains all of the overlaps per each network, and another with a binarized (yes/no)
### Uses: Trying to figure out which fascicles are in the yeo 7 network for dimensionality reduction for use in later regressions (i.e. decrease # comparisons by only looking at fascicles within yeo 7 networks)
### Dependencies: This script requires afni to be installed (currently using 20.1)

#output directory
outdir="/project/msdepression/results/"

#assemble yeo 7 networks

yeo_7_net_list=("VIS"
                "MOT"
                "DA"
                "VA"
                "LIM"
                "FP"
                "DM")

#set up output file names
all_net_overlap_proportions="${outdir}/yeo_7_network_overlap_proportions.txt"
all_net_overlap_proportions_binarized="${outdir}/yeo_7_network_overlap_proportions_binarized.txt"

#set counter to keep track of whether it is the first iteration (and you need to do a special column add), or just take the last line and pr it
counter=1
for network in "${yeo_7_net_list[@]}"; do
	#set outfile
	outfile="/project/msdepression/results/streamline_volume_within_${network}_network.csv"

	#set template directories, will be making our resampled mask from within this
	template="yeo_7_net_${network}.nii"
	template_dir="/project/msdepression/templates/Yeo_JNeurophysiol11_MNI152/"
	resampled_filename="resampled_${template}"
	template_fullpath="${template_dir}/${template}"

	#set fascicle directory
	fascicle_direc="/project/msdepression/templates/dti/HCP_YA1065_tractography/"
	fascicle_type="association"
	fascicle_for_resampling="AF_L.nii.gz"

	#set home directory
	homedir="/project/msdepression/scripts/"

	#initiate csvs
	rm -f $outfile
	touch $outfile
	echo "fascicle,num_voxels_total,non_zero_voxels_in_${network}_map,prop_in_mask_${network}" >> $outfile

	#resample yeo_7_net_${network}.nii to match sample fascicle - AF_L.nii.gz
	if [ -f "${template_dir}/${resampled_filename}" ]; then
		rm -f ${template_dir}/${resampled_filename}
	fi
	3dresample -master ${fascicle_direc}/${fascicle_type}/${fascicle_for_resampling} -prefix ${template_dir}/${resampled_filename} -input ${template_fullpath} -rmode NN

	#go through each fiber, get volume, and store it in csv
	fiber_bundle_type_list="association cerebellum cranial_nerve projection commissural"
	for fiber_bundle_type in ${fiber_bundle_type_list}; do
	    echo "Fiber bundle type is " $fiber_bundle_type
	    fascicle_volumes=$(ls ${fascicle_direc}/${fiber_bundle_type}/*.nii* | grep -v "_mask") #list all files, exclude ones with mask in them
	    for fascicle in ${fascicle_volumes}; do
		    fascicle_prefix=$(echo $fascicle | perl -pe 's/.*\/(.*).nii.gz/$1/g')
		    num_voxels_whole_mask=$(3dmaskave -quiet -mask SELF -sum ${fascicle})

		    #remove previous mask if already made
		    if [ -f "${fascicle_direc}/${fascicle_type}/${fascicle_prefix}x${network}_mask.nii.gz" ]; then
			    rm -f ${fascicle_direc}/${fascicle_type}/${fascicle_prefix}x${network}_mask.nii.gz
		    fi

		    3dcalc -a ${template_dir}/${resampled_filename} -b ${fascicle} -expr 'a*b' -prefix ${fascicle_direc}/${fascicle_type}/${fascicle_prefix}x${network}_mask.nii.gz
		    num_nonzero_volumes=$(3dmaskave -quiet -mask SELF -sum ${fascicle_direc}/${fascicle_type}/${fascicle_prefix}x${network}_mask.nii.gz)
		    prop_in_mask=$(echo ${num_nonzero_volumes}/${num_voxels_whole_mask} | bc -l)
		    echo "num_voxels" $num_voxels_whole_mask "num_nonzero" $num_nonzero "prop_in_mask" $prop_in_mask
		    echo "${fascicle_prefix},${num_voxels_whole_mask},${num_nonzero_volumes},${prop_in_mask}" >> $outfile
	    done
	done

	#add column to output file
	if [ ${counter} == 1 ]; then
		#remove the file if it exists
		rm -rf ${all_net_overlap_proportions}
		#take the 1st and 4th columns and write new file
		cat ${outfile} | cut -d ',' -f 1,4 > ${all_net_overlap_proportions} 
	else
		#paste the last column into the building table
		cat $outfile | cut -d ',' -f 4 > to_add.txt
		pr -mts, ${all_net_overlap_proportions} to_add.txt > temp.txt

		#remove to_add file
		rm to_add.txt

		#move temp to the file, so everything is up to date
		mv temp.txt ${all_net_overlap_proportions}
		
	fi
	((counter++))
done

#binarize the all_net_overlap_proportions file, takes every value and puts a 0 - this takes the ,, cases and makes them 0s. And then it takes any decimals (meaning some overlap, makes them 1s)
cat ${all_net_overlap_proportions} | perl -pe 's/,/,0/g' | perl -pe 's/0\.\d+/1/g' > ${all_net_overlap_proportions_binarized}
```

#### 20220628
[x] run analyses looking at depression, age, sex, within fp
```{bash}
sh #doesn't work with zsh
scp eballer@transfer.pmacs.upenn.edu:/project/msdepression/results/yeo* /Users/eballer/BBL/msdepression/results/.
```

check out /Users/eballer/msdepression/scripts/yeo_7_network_analyses_20220628

#### 20220629
realized that my depression network analyses were using the clusterized, binarized mask that was thresholded (not the general map) that is so big and gross. Will need to ask matt how he picked the range of -0.1317 to 0.1317. From Shan, this range is in R's. With a sample size of 713, the corresponding T value is 3.50 (or p<0.0005 uncorrected)

 Meeting with Ted
 

3dclust -1Dformat -nosum -1dindex 0 -1tindex 0 -1noneg -2thresh -0.1317 0.1317 -dxyz=1 -savemask Clust_mask 1.01 20 /Users/mcieslak/Desktop/AllFX_wmean.nii. For my analyses, I used: Depression_Clust_mask_roi_binarized.nii.gz, which is this mask copied. Give an underlay, check if cerebellum . 1) overlap % with binarized dep network (3.09) , which is redo the depression network stuff but use different brain map. 2) average t value for each fascicle  3) average t value for overlap zone of fascicle w/depression mask . 4) Possibly weight it by the % lesion affecting fascicle by depression T (so this is a depression dysconnectome score. this is how much of the fascicle is affected multiplied by the T value of the overlap depression/fascicle area). Brain Smash â€“ Spin test 

- gonna remake the depression mask at T = 3.09 (p <0.001); r = 0.115 (with df 713)

```{bash}

#clusterize and binarize in 1 step
3dclust -1Dformat -nosum -1dindex 0 -1tindex 0 -1noneg -2thresh  -3.09 3.09 -dxyz=1 -binary -savemask Dep_clust_T_3_09_binarized.nii 1.01 20 /Users/eballer/BBL/msdepression/templates/harvard_depression/DepressionCircuit_t.nii

#nonbinarized
3dclust -1Dformat -nosum -1dindex 0 -1tindex 0 -1noneg -2thresh  -3.09 3.09 -dxyz=1 -savemask Dep_clust_T_3_09.nii 1.01 20 /Users/eballer/BBL/msdepression/templates/harvard_depression/DepressionCircuit_t.nii


#calculate a mask that is the T values within the clusters within the depression mask
3dcalc -a Dep_clust_T_3_09_binarized.nii -b DepressionCircuit_t.nii -expr 'a*b' -prefix Dep_clust_T_3_09xDep_circuit_T.nii

#copy to pmacs
scp Dep_clust_T_3_09* eballer@transfer.pmacs.upenn.edu:/project/msdepression/templates/harvard_depression/.
scp DepressionCircuit_t.nii eballer@transfer.pmacs.upenn.edu:/project/msdepression/templates/harvard_depression/.

#go onto pmacs
ssh -Y eballer@scisub.pmacs.upenn.edu

#go into scripts directory
cd /project/msdepression/scripts/

#copy 
cp calc_vol_fascicles_within_depression_mask.sh calc_vol_fascicles_within_depression_mask_3_09.sh

#change line in calc_vol_fascicles_within_depression_mask_3_09.sh
vim calc_vol_fascicles_within_depression_mask_3_09.sh

# copy results back local
scp eballer@transfer.pmacs.upenn.edu:/project/msdepression/results/streamline_volume_within_dep_network_3_09.csv /Users/eballer/BBL/msdepression/results/.
```

#### 20220630
 [x] do analyses with new masks, see how it compares. More values in there, results largely unchanged
 
#### 20220701-20
Whoops, forgot to record! Trying to address a few questions - we will use the 3.09 mask going forward. There are clearly differential proportions of fascicles within the depression network. So I sorted them by % overlap, it looks generally distributed, plan to take top quartile and consider that to be the depression mask. 

Then the question becomes, what is the "nondepression" mask. Is it anything not in depression mask? Is it areas where there is NO overlap? Either way, there is much higher disease in areas within the depression mask versus outside of it. 

Then the question is, the cranial nerves basically have no overlap. Is this because they are poorly sampled by mimosa/brain scan? 
If they are well sampled, positives for including them - you can say that disease is more likely in cortical versus cranial nerve tracts. Given that MS affects any part of the CNS, the fact that there is some relative sparing of the cranial nerves could be meaningful
Cons: If they are not well-sampled, it is useless. Also, if the depression map never went down that far, then it would be hard to say to include them or not. 
Also, there would be no way for the depression map to include them, since the depression map only includes things with bold signal, and cranial nerves aren't actually connecting brain to brain. 

- of note, cerebellum is in mask, and it is sampling inferiorly enough to grab brainstem (the overlays I have aren't lining up great, but it does look like mask lines up with brainstem)

- had a quick panic attack when I saw that our depression circuit on my local machine didn't line up with anything I had locally. But I double checked. On pmacs, in script: calc_vol_fascicles_within_depression_mask.sh, there is a line where I resample the depression mask to be in the same space as the AF_L.nii, which lines up with MNI152_T1_1mm mask (/Users/eballer/BBL/msdepression/templates/dti/mni_icbm152_t1_nlin_asym_09a/mni_icbm152_t1_tal_nlin_asym_09a.nii). There is some crap outside the brain for this, should disappear when multiplied with mimosa mask. Similarly, the fascicles themselves (i.e. the volume in AF_L look great and line up perfectly). I don't think this harvard depression map is the best, to be honest. Could also be that the resampling would be better not w/NN but something else.

[x] sensitivity analysis looking just at brain regions within cerebrum (i.e. drop cranial nerves)

  Results:
  
  When comparing lesion burden in depressed vs healthy
    1) Overall lesion burden, findings no longer significant
 
    2) Lesion burden within the 25% mask, patients with depression have MORE disease (32%) than healthy patients (27%) within this network (p=0.047)
    
    3) Lesion burden within nondep network, depressed patients have more disease 23% vs 20%  p = 0.049
    
    4) Lesion burden within bottom 75%, inverse relationship, depressed patients have less disease (23%) than healthies (27%) p = 0.023
       - could be in line w/the fox work that suggests that disease in non-dep network could be protective
    
  When looking at network enrichment
    1) in the absence of the cranial nerves, more disease in areas than interact w/depression network vs places that never had any overlap  
      - #mean dep_net = 31%, mean non_dep_net =  22%, p 8.58 x 10^-12
      
    2) in the absence of the cranial nerves, more disease in the top 25% than in areas that never intersected with depression map 
      - #mean dep net = 30%, mean non_dep_net = 22%, p 7.3* 10^-8
      
    3) in the absense of cranial nerves, the difference between the top 25% and the bottom 75% is no longer significant
      - #mean dep net = 30%, mean bottom 3 quartiles = 29, p = 0.52

some notes: If I exclude cranial nerves up front, the "depression" network will have 19 regions (rather than 22)
[x] message matt about what to do with depression network, inclined to leave it as is right now, but in the future, probably use something else


using round- lm (dep vs healthy p 0.049, but t test between two groups doesn't work)



[x] come up with EXACT verbiage on how to describe depression mask versus lesion masks
  - 1) First, we have to define what the fascicles are considered to connect the depression mask
  - We start with a functional mask from harvard. It was generated using lesion network mapping.
  - 14 datasets were used, including stroke, dbs (parkinson's), and tms datasets
  - Per article: The location of each lesion or brain stimulation site (Fig. 2aâ€“c, top panels) was mapped to an underlying brain circuit using a large normative connectome database (n=1000) and previously validated methods (Fig. 2aâ€“c, bottom panels)5. The normative connectome was used to estimate connectivity of each lesion or stimulation site to every voxel in the brain. At each voxel, a Pearson r-value was computed for the correlation between depression score and lesion or stimulation site connectivity to that voxel (Fig. 2aâ€“c, right panels), yielding a population-derived â€œcircuit mapâ€ for each of the 14 datasets (Supplementary Figure 1). We generated a combined depression circuit map by taking the mean of all 14 circuit maps, weighted by the sample size of each dataset (Fig. 5a). Of note, lesions are expected to positively correlate with symptoms, whereas the inverse of tms sites and was (so connectivity in these areas was inverted)
  
  - We take that mask, threshold it at 3.09 (p=0.001, uncorrected), and binarize it. 
  - We then go through each of the 87 fascicles, and calculate what proportion of each fascicle overlaps with the depression network, scaled by the overall volume of the fascicle
  - We then rank these fascicles by their overlap
  - We consider the final fascicle "mask" to be the top 25% of fascicles (i.e. the top quartile according to proportion of fascicle affected)
  - These fascicles (22 total), are then called the depression "mask"
  - after this step, the proportion of overlap is no longer integrated into analysis, it is solely used to rank the fascicles to define the network. 
  
  -2) Having defined which fascicles are associated with the depression mask, we can now look subject data in individual fascicles, as well as comparing fascicles within the WM depression network versus outside of it.
  
#### 20220722

[] make sure graphs have value for y axis 

[] speak with matt 
  - about mask in general, seems crappy  
     - it is, but it is what we have
  [x] email Shan, mni 2009b
  [x] Yes to exclude cranial nerves
[o] how about nondep mask looking at 25% low end OR 3.09 in opposite direction?
 - looking at bottom quartile, no cranial nerves - no overall diffs in depression/healthies, but more disease w/in dep network in depressed, no differences in disease in bottom 75% or bottom quartile
 - findings of more disease in depression network than outside in MS go away. But honestly, I'm okay with this. I want to use the no cranial nerves mask, can say it is due to poor coverage?
 {} will instead making 2 graphs, T values per fascicle (bar graph), ranked by overlap with depression map
 {} plot, x axis overlap w/depression map, y axis t value of group difference
 
[x] another potential avenue, ranking each of the clusters based on their mean t value(essentially don't binarize map), and using that to multiply w/overlap proportion - crap, 

[x] make some pictures of the actual mask coverage. 

[] message bart re: mixed model w/gam

[x] Make a plot of overlap of each tract w/depression network on x axis (so each fiber gets a space, 77 total), y axis is the t value of depression vs control w/in that fascicle. Try to fit a line, see how it looks. Might be an easier way than randomly thresholding.
 
#### 20220726-27
[x] redid these analyses instead looking at how much volume was affected in each fascicle (not correcting for size of the fascicle). 
   - Results
   - Overall fascicle volume affected greater in depressed vs nondep
   - Driven by more fascicle loss w/in fibers that connect depression network
   - No differences between diagnostic groups in bottom 25th percentil or bottom 75%
   - For each fascicle, the higher its overlap w/the depression network, the bigger the the patient > control T test t value is
   
#### 20220728
[x] Going to now just compare overall volume of the lesions (irrespective of fascicles that run through) for each subject
  - Ideal finding would be that the overall volume of lesions isn't different between groups, but that it is only when you look at streamlines affected that you get the money. 
  - Alternatively, if the lesion volume also discriminates, that is cool, too. Way to test effect size? Whether they can be viewed together? Wonder how it correlates with symptoms (i.e. fascicle view helps correlate with dimensions of psychopathology)
 - after making the file, I'll read it in to r, merge with the big spreadsheet, and then just do the patients vs controls analysis

   
```{bash}
ssh -Y eballer@scisub.pmacs.upenn.edu
cd /project/msdepression/scripts
xbash
module load afni_openmp/20.1 
sh get_volume_of_mimosa_lesions.sh 
#results written to /project/msdepression/results/mimosa_binary_masks_hcp_space_20211026_n2336_volumes
exit pmacs
cd /Users/eballer/BBL/msdepression/results
scp eballer@transfer.pmacs.upenn.edu:/project/msdepression/results/mimosa_binary_masks_hcp_space_20211026_n2336_volumes .
```

```{bash get_volume_of_mimosa_lesions.sh }
#!/bin/bash

#########     Welcome to  get_volume_of_mimosa_lesions.sh !  ##########3
## The purpose of this script is to extract the overall volume of lesion burden for each mimosa mask. 
## The goal is to use the output to answer the question: Does overall lesion burden (quantified by volume of le
sions), irrespective of location, relate to depression diagnosis?

### Pre: File containing full paths to the mimosa binary masks:  /project/msdepression/data/melissa_martin_file
s/csv/mimosa_binary_masks_hcp_space_20211026_n2336
### Post: File containing ACCESSION_NUM, EXAM_DATA, volume_of_mimosa_lesions
### Uses: 	1) Reads in the file with full paths
###		2) Extracts the accession number and exam date
###		3) Performs 3dmaskave -quiet -mask SELF -sum ${binary_map} and writes to a file
### Dependencies: 1) Requires afni, so you need to xbash, and module load afni<tab complete>

### Opening Script: If nothing is entered, let person know we are using default mimosa path file, otherwise use
 file on command line

echo "Greetings and welcome to the get_volume_of_mimosa_lesions script"
echo "This script takes a file with full paths to mimosa binary maps, and returns a file that has the accession
 number, exam data, and overall volume of lesions in that map"
#set default path
default_mimosa_path="/project/msdepression/data/melissa_martin_files/csv/mimosa_binary_masks_hcp_space_20211026
_n2336"

echo "Default mimosa path $default_mimosa_path"
#set output directory for the volumes file
output_direc="/project/msdepression/results/"

if [ $# == 0 ]
then
    echo "We will use the default mimosa files path" $default_mimosa_path
    mimosa_files_path=$default_mimosa_path
else  
    mimosa_files_path=$1
fi

echo "Mimosa files path" $mimosa_files_path
#### initiate new file

#append "_volumes" to the end of the path
suffix=$(echo ${mimosa_files_path} | perl -pe s'/.*\/(.*)/$1/g')
output_csv=$output_direc/$suffix"_volumes"

#get rid of old file if it exists, write new one and put in headers
rm -f $output_csv
touch $output_csv
echo "ACCESSION_NUM,EXAM_DATE,volume_of_mimosa_lesions" >> $output_csv

#loop through each file in the mimosa_file_path, extract accession/exam date, calculate volume, write to file
mimosa_files=$(cat ${mimosa_files_path})
for mimosa_file in $mimosa_files; do
    	echo "Mimosa file is" $mimosa_file
 
	#pulls out accession number and date, separated them by a comma
    	subj_sess=$(echo ${mimosa_file} | perl -pe s'/.*sub-(.*)\/ses-(.*)\/r.*/$1,$2/g')
    
	#gets volume of binary mask
	volume=$(3dmaskave -quiet -mask SELF -sum ${mimosa_file})
        
	#writes to output file
	echo "${subj_sess},$volume" >> $output_csv
done


```


```{r bootstrap}

##### proportion
# 95% confidence intervals for the correlation
set.seed(1)
tval <- function(formula, data, indices) {
  d <- data[indices,] # allows boot to select sample
  fit <- lm(formula, data=d)
  return(summary(fit)$coefficients[2,3])
}

data_frame_dep_v_nondep_t_x_prop_dep_mask_overlap <- subset(df_fascicle_dep_mask_overlap_t_value, select = c("depression_mask_overlap","dep_vs_healthy_t"))
results_prop <- boot(data=data_frame_dep_v_nondep_t_x_prop_dep_mask_overlap, statistic=tval,
   R=10000, formula=dep_vs_healthy_t~depression_mask_overlap)
print(results_prop) #actual 2.62, CI 0.701, 4.553)
plot(results_prop)
boot_results_prop.ci <- boot.ci(results_prop, conf=0.95, type="bca", index=1)
print(boot_results_prop.ci)

#manually calculating P from CI, from interwebs
est=results_prop$t0
l=boot_results_prop.ci$bca[4]
u=boot_results_prop.ci$bca[5]

#1) SE=(u-l)/2*1.96
se=((u-l)/(2*1.96))
#2) z=Est/SE
z=est/se
#3) p=exp(-0.717*z - 0.416*z^2)
p=exp((-0.717*z) - (0.416*(z*z)))
print(p) #p=0.008

##### volume
# 95% confidence intervals for the correlation
set.seed(1)
data_frame_dep_v_nondep_t_x_vol_dep_mask <- subset(df_fascicle_dep_mask_volume_t_value, select = c("dep_vs_healthy_t", "volume_in_dep_mask"))

results_vol <- boot(data=data_frame_dep_v_nondep_t_x_vol_dep_mask, statistic=tval,
   R=10000, formula=dep_vs_healthy_t~volume_in_dep_mask)
print(results_vol)
plot(results_vol)
boot_results_vol.ci <- boot.ci(results_vol, conf=0.95, type="bca", index=1)
print(boot_results_vol.ci)

#get p from CI
#manually calculating P from CI, from interwebs
est=results_vol$t0
l=boot_results_vol.ci$bca[4]
u=boot_results_vol.ci$bca[5]

#1) SE=(u-l)/2*1.96
se=((u-l)/(2*1.96))
#2) z=Est/SE
z=est/se
#3) p=exp(-0.717*z - 0.416*z^2)
p=exp((-0.717*z) - (0.416*(z*z)))
print(p) #p=0.001

```
    
    Take home:

Paper figures
1) Demographics/how samples were calculated
2) Method
3) method for calculating depression map
4) No difference in overall lesion volume between the groups (violin, the figure with SEM makes it look like there is a difference)
5) Overall lesion breakdown across all groups, then divided by depressed & healthy (maybe, maybe not)
6) If you look at the volume of the streamlines affected, Depressed have more volume loss than controls
7) And specifically, that loss difference is driven by loss in depression network (areas with top percentile of overlap with depression network drive it)
8) The more overlap a fascicle has (in either volume of proportion of streamline) with the depression network, the higher the T value of the diagnostic differences (this could also be two part figure, with 5 above)

[x] taki wants me to do bootstrap to get CIs for the t value ~ overlap with depression network analysis. Boot in R can do this
    Take data, resample subjects, w/ replacement, refit, do 1000 times or 10,000 times and confidence interval
    https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/
    https://www.statmethods.net/advstats/bootstrapping.html
    

#### 20220802

Promis scores
1) First, clean up the promise scores
    [x] get rid of text in the fields (good/bad/whatever)
    [x] change date to be same format as our main spreadsheet
    
2) Get a sense of how many people in our sample have promise scores
  - sort promise scores by empi and date, take unique, merge with existing data set and count
  
  https://stackoverflow.com/questions/43472234/fastest-way-to-find-nearest-value-in-vector
1) First, get a sense of how many people in our sample

n = all promis - 1694 scores, 501 unique subjects. 
398 in our overall pull (granted this pull went up to 2022, our ms pull was in 2021), 116 unique empis
depressed promis - 46 unique
nondepressed promis - 36 unique
depressed + nondepressed prop - 82 unique


Look at distribution

MS lesion age, predict age in a ridge regression. Predict how old someone is how bad their lesions are. Your disease progression is better or worse than espected. 
#### 20220803

[x] still working on getting pvalue from boot - yes, it works! Needed boot.pval extra package, and switched to perc instead of bca
  - we originally used bca, but the pval command was breaking for some reason we couldn't quite get (something about being out of range). Per Taki-
  
  I took a quick peek and if you're using the method described by Altman it totally makes sense you'll get something slightly different; he made a normal assumption and used that for the interval inversion. This, rather, is totally empirical. As for why it's not working with bca, that's a different question. I'm honestly not sure. We could try to troubleshoot this together, but TBH I think i'd just slide back into using the  percentile bootstrap since it's legit here as well. The bca is considered better, but it's not the kind of thing that keeps me up at night personally. Does that make sense?



----------
1,554 analyses total! Nothing significant
[x] fascicles x promis score in each individual fascicle (both proportion and volume) -NS
[x] broken up by dx
[x] within dep net
[x] outside dep net
----------

-----------
66 analysis total, nothing significant
[x] fascicles x promis score in each network (total, depression 25, non dep 75%, both proportion and volume)
[x] broken up by dx
[x] within dep net
[x] outside dep net

#### 20220805
[x] trying out correlations with effect sizes instead of Ts, wow this makes results even better, they all work

#### 20220810
[x] make sure the mutate command is okay, somehow I think we might be undercounting the healthy group. Okay ish now, but somehow the depGroupVar has a lower number than chaining together this command:  df_good_mimosa_unique %>% filter(Has.depdx == FALSE) %>% filter(On.Antidepressants == FALSE) %>% filter(PHQ.2_zero == TRUE). Double checked the logic and it looks okay
- I think it has something to do with when I include people if they have a positive PHQ2 OR 9 (PHQ2 | PHQ9): Checked this, the | works just fine
- Will need to make sure to write the draw io to match my mutate commands. Must be that when I do the filter separately, I am counting some 0s that I shouldn't be counting in phq2. 

Checks
- x <-data_empi_acc_f_phq %>% filter(!Has.depdx) %>% filter(!On.Psych.Meds) %>% filter(PHQ.2_zero | PHQ.9_zero)
- length(unique(x$EMPI)) = 488
- length(data_empi_acc_f_phq$EMPI[data_empi_acc_f_phq$true_healthy== 1]) = 2608
- length(unique(data_empi_acc_f_phq$EMPI[data_empi_acc_f_phq$true_healthy== 1])) = 488

- maybe some people with phq2_0 are actually Na?
- x <-data_empi_acc_f_phq %>% filter(!Has.depdx) %>% filter(!On.Psych.Meds) %>% filter(PHQ.2_zero==1) = 2595, 485 unique
- x <-data_empi_acc_f_phq %>% filter(!Has.depdx) %>% filter(!On.Psych.Meds) %>% filter(PHQ.9_zero==1) = 13, 3 unique
- 13+2595 = 2608; 485+3 = 488
- these all work out

- so is it if you take unique first, some columns are missing? but why would that give you more phq2s that are okay

- Maybe it is merge? First, from ? merge : The rows in the two data frames that match on the specified columns are extracted, and joined together. If there is more than one match, all possible matches contribute one row each. < this should be handled when I take unique later>

- seems to be working now when I call unique at the end. DOuble check what happens when I call unique at the beginning. 

- tried getting unique values in the data_empi_acc_f_phq before merging w/ lesion volumes:
data_empi_acc_f_phq <- data %>% 
   mutate(across(.cols = columns_to_make_integer, .fns = as.integer)) %>%
   mutate(sex_binarized = ifelse(SEX == "MALE", 1, 2)) %>%
   mutate(osex = ordered(sex_binarized,levels = c(1,2), labels = c("Male","Female"))) %>%
   mutate(race_binarized = ifelse(RACE == "WHITE", 1, 2)) %>%
   mutate(orace = ordered(race_binarized,levels = c(1,2), labels = c("White","Non-white"))) %>%
   mutate(EXAM_DATE = as.Date(BEGIN_EXAM_DTTM, format = "%m/%d/%y")) %>% 
   mutate(EXAM_DATE = gsub(EXAM_DATE, pattern = "-", replacement = "")) %>%
   mutate(BEGIN_EXAM_DTTM = as.Date(BEGIN_EXAM_DTTM, format = "%m/%d/%y")) %>% #make sure to actually save it as date object for later processing
   mutate(EMPI = as.factor(EMPI)) %>%
   
  ###
  group_by(EMPI) %>% 
  arrange(EXAM_DATE) %>% 
  slice(1) %>% 
  ungroup() %>%
  ###
   mutate(On.Psych.Meds = ifelse(On.Psych.Meds == "True", 1, 0)) %>%
   mutate(On.Antidepressants = ifelse(On.Antidepressants == "True", 1, 0)) %>%
   mutate(Has.PHQ2 = ifelse(Has.PHQ2 == "True", 1, 0)) %>%
   mutate(Has.PHQ9 = ifelse(Has.PHQ9 == "True", 1, 0)) %>%
   mutate(Has.depdx = ifelse(grepl("F3", ICD10), 1, 0)) %>%
   mutate(PHQ.2_modsev_dep_sxs = ifelse((!is.na(PHQ.2) & PHQ.2 >= 3), 1, 0)) %>%
   mutate(PHQ.9_modsev_dep_sxs = ifelse((!is.na(PHQ.9) & PHQ.9 >= 10), 1, 0)) %>%
   mutate(PHQ.2_mild_dep_sxs = ifelse((!is.na(PHQ.2) & PHQ.2 > 0 & PHQ.2 < 3), 1, 0)) %>%
   mutate(PHQ.9_mild_dep_sxs = ifelse((!is.na(PHQ.9) & PHQ.9 > 0 & PHQ.9 < 10), 1, 0)) %>%
   mutate(PHQ.2_zero = ifelse((!is.na(PHQ.2) & PHQ.2 == 0), 1, 0)) %>%
   mutate(PHQ.9_zero = ifelse((!is.na(PHQ.9) & PHQ.9 == 0), 1, 0)) %>%
   mutate(dep_by_dx_phq = ifelse((Has.depdx | PHQ.2_modsev_dep_sxs | PHQ.9_modsev_dep_sxs),1,0)) %>%
   mutate(dep_by_dx_phq_antidep = ifelse((Has.depdx | On.Antidepressants | PHQ.2_modsev_dep_sxs | PHQ.9_modsev_dep_sxs),1,0)) %>%
   mutate(true_healthy = ifelse((!Has.depdx & !On.Psych.Meds & (PHQ.2_zero | PHQ.9_zero)), 1, 0)) %>%
   mutate(dep_by_dx_phq_meds_healthy_phq0_no_psych_meds = ifelse(dep_by_dx_phq_antidep | true_healthy, 1, 0)) %>%
   rowwise(ACCESSION_NUM) %>%
   mutate(depGroupVar =
            sum(c(dep_by_dx_phq_meds_healthy_phq0_no_psych_meds,dep_by_dx_phq_antidep))) %>%#you get an extra point if you are in the depression group, so the end result is dep = 2, healthy = 1, 0 for exclude
   ungroup()

-Did not work because it took out people who didn't have good mimosas, so by the time you merge w/good mimosas, only 158 scans left.

- Now going to look at the empis that make it to the 168 group and 148 group

x <- df_demo_and_fascicles %>% filter(Has.depdx==FALSE) %>% filter(On.Antidepressants == FALSE) %>% filter(PHQ.2_zero == TRUE) %>% group_by(EMPI) %>% 
+     arrange(EXAM_DATE) %>% 
+     slice(1) %>% 
+     ungroup() 
> dim(x)
[1] 168 159
> x_empi <- x$EMPI

y_empi <- df_good_mimosa_unique$EMPI[df_good_mimosa_unique$true_healthy==TRUE]
> length(y_empi)
[1] 148

> z_empi <- setdiff(x_empi,y_empi)
> z_empi
 [1] "1000443363" "1000576093" "1000616211" "1000680873" "1000731479" "1000758897" "1000782730" "1001091352" "1001387420" "1001760723" "1001776245" "1003146950"
[13] "1003642810" "1003709298" "1003867245" "1003873441" "1004564376" "1004566947" "1004641094" "8000342932" "8440021590"
> length(z_empi)
[1] 21


> df_demo_and_fascicles$depGroupVar[df_demo_and_fascicles$EMPI == 1000443363]
[1] 0
> df_demo_and_fascicles$On.Antidepressants[df_demo_and_fascicles$EMPI == 1000443363]
[1] 0
> df_demo_and_fascicles$Has.depdx[df_demo_and_fascicles$EMPI == 1000443363]
[1] 0
> df_demo_and_fascicles$PHQ.2_zero[df_demo_and_fascicles$EMPI == 1000443363]
[1] 1
\> df_demo_and_fascicles$PHQ.9[df_demo_and_fascicles$EMPI == 1000443363]
[1] NA

AH! I figured it out. I didn't filter out people who are ALSO NOT ON PSYCH MEDS. My mistake in that line was not including not on psych meds.

x <- df_demo_and_fascicles %>% filter(Has.depdx==FALSE) %>% filter(On.Psych.Meds== FALSE) %>% filter(PHQ.2_zero == TRUE) %>% group_by(EMPI) %>%  arrange(EXAM_DATE) %>%   slice(1) %>% ungroup
> dim(x)
[1] 147 159

GOT IT !!!!

#### 20220808

Another strange idea that is not needed right now, but what about defining depression even more data driven.

Tract filtration done normally.
For each tract, instead of looking at its overalp in proportion or volume in depression network, do some sort of cortical parcellation (schaefer for example), and calculate the volume or proportion of overlap of each full tract to the parcellation. calculate prop overlap of each individual fiber to its overlap with each of schaefer regions (so like 200 * 77 matrix).
Map to yeo networks, compare between healthy and control. Or you can hydra on the yeo networks, or w/in outside depression network, or just look at indiv fascicles. This actually isn't that thought out. Or some sort of spin for network correspondence between network structure in depression as opposed to controls.

[x] look at what happens when you define depression diagnosis by volume rather than proportion overlap. I.e. a fascicle is in the "depression network" if the volume that it shares with the depression network is in the top 25%. In this situation, we still see that overall, depressed have more disease (i.e. more volume affected) irrespective of dx (p=0.045). 
  [x] Within dep network (as defined by volume), 
  [x] dep disease > nondep disease in dep network, p=0.0.034,
  [x] dep disease and nondep disease in bottom 75%, p = 0.071 (NS)

dep_network_names_top_quartile_no_cranial_nerves_by_vol
 [1] CC      AF_L    SLF2_R  SLF3_R  FAT_L   TR_S_R  SLF2_L  AF_R    TR_S_L  FAT_R   CS_S_R  CPT_F_R CPT_P_L ILF_R   CPT_P_R CS_S_L  PAT_R   MdLF_L  CBT_R  

dep_network_names_bottom_3_quartiles_no_cranial_nerves_by_vol
  [1] C_FPH_L C_FPH_R C_FP_L  C_FP_R  C_PH_L  C_PHP_L C_PHP_R C_PH_R  C_R_L   C_R_R   EMC_L   EMC_R   IFOF_L  IFOF_R  ILF_L   MdLF_R  PAT_L   SLF1_L  SLF1_R 
[20] SLF3_L  UF_L    UF_R    VOF_L   VOF_R   CB_L    CB_R    ICP_L   ICP_R   MCP     SCP     V       AR_L    AR_R    CBT_L   CPT_F_L CPT_O_L CPT_O_R CS_A_L 
[39] CS_A_R  CS_P_L  CS_P_R  CST_L   CST_R   DRTT_L  DRTT_R  F_L     F_R     ML_L    ML_R    OR_L    OR_R    RST_L   RST_R   TR_A_L  TR_A_R  TR_P_L  TR_P_R 
[58] AC

I actually think we should use proportions for this, because if we define depression just based on volume, which does work, it is never possible that the volume of small fascicles will contribute meaningfully, even though they may play a big role. Additionally, if you just use volume, you could get a fiber which donates a ton to depression network by volume, but half of that fascicle provides information to outside the depression network. It seems a little more logical to define values as within the depression network based on how much of the total fascicle dead ends into the depression network as compared to its total volume. But luckily the findings are the same, irrespective of whether you define the 25% based on volume or proportion.

One could also make a case that even if, lets say, only 30% of the AF lands in the depression network, but the 99% of the depression network is occupied by AF streamlines, then it should be ranked really high, as opposed to a tiny fascicle where the whole thing lands in the depression network, but it only accounts for 1% of the network. And it is just a good question of what matters. Thank goodness they both work. 

Making DSI studio tracts
- if it doesn't work to add the depression network as roi, make sure to add the asym template from the harvard depression network first, and then the best mask to use is Dep_clust_T_3_09_binarized.nii.

##### 20220810
[] do proportion effect size plot if you'd like, not done right now
[] Figures
  [] Overall fascicles, highlight optic radiations, etc, use viridis and cool colors
    - have to do volume, not just proportion. I am thinking - a viridis of some sort to show overall volume of fascicles across people, then a bar to show top chunk, and separate out a graph of top 25% and bottom 75%. 
    - Could also find a way to show volume in each fascicle in dep vs non
    - Going to also try in afni to multiple each fascicle by its count, sum them up, and display over template brain. 
```{bash}
# go to directory
cd /Users/eballer/BBL/msdepression/templates/dti/HCP_YA1065_tractography

#make new direc if it doesn't exist
mkdir -p niftis_excluding_cranial_nerves

#copy non-cranial nerves
cp association/*nii* cerebellum/*nii* commissural/*nii* projection/*nii* niftis_excluding_cranial_nerves/.

#cd into directory
cd niftis_excluding_cranial_nerves

#read in file with proportions

```

```{bash make_afni_map_w_fascicles_colored_by_prop_or_volume}
#!/bin/bash

##### Welcome to make_afni_map_w_fascicles_colored_by_prop_overlap ###
### Pre: A file that has two columns, no headers. First column is the abbreviation of a fascicle, second is proportion overlap (or volume overlap)
### Post: A nifti where each fascicle is colored by the proportion of overlap, or any value you give it
### Uses: I wanted to find a way to show, in a brain, which fascicles have the most overlap with lesions (though this can be done w/depression, non-dep, volume). This will go through a table, and for each fascicle, multiply it times the value in the second column, add a suffix, and then at the end, sum them all to make a final image
### Dependencies: Afni

#change this if doing on pmacs
homedir="/Users/eballer/BBL/msdepression/"

default=${homedir}/results/fascicle_mean_proportion_overlap_nfasc_77.csv
default_suffix="prop"

if [ $# == 0 ]
then
    echo "We will use the default path file" $default
    fascicle_file=$default
else  
    fascicle_file=$1
fi


echo "File being read is "$fascicle_file

fascicles=$(cat $fascicle_file)

cd ${homedir}/templates/dti/HCP_YA1065_tractography/niftis_excluding_cranial_nerves

(pwd)
for fascicle in ${fascicles}; do
        # extract fascicle name and value
        fascicle_name=$(echo ${fascicle} | perl -pe 's/(.*),.*/$1/')
        fascicle_value=$(echo ${fascicle} | perl -pe 's/.*,(.*)/$1/')
        
        # remove nifti w/values if already there
        rm -rf ${fascicle_name}_${default_suffix}.nii.gz

        #take the fascicle .nii, multiply it with the value
        command=$(echo 3dcalc -a ${fascicle_name}.nii.gz -expr \'a*${fascicle_value}\' -prefix ${fascicle_name}_${default_suffix}.nii.gz)
        echo "Here is the command: "${command}
        
        #run command, have to do separately to get variable into afni command
        eval "${command}";
done

#remove old file
rm -rf fascicle_${default_suffix}_sum.nii.gz
rm -rf fascicle_${default_suffix}_max.nii.gz
 
all_files=$(ls *${default_suffix}.nii.gz)

#take sum
command_sum=$(3dMean -prefix fascicle_${default_suffix}_sum.nii.gz -sum ${all_files})
eval "${command_sum}";

#take max
command_max=$(3dMean -prefix fascicle_${default_suffix}_max.nii.gz -max ${all_files})
eval "${command_max}";

cd ${homedir}/scripts
```

    
  [] Age effects perhaps
  [] Rank of fascicles based on overlap in proportion (and or volume, or both) w/ depression network
  [x] lesion overall burden
  [x] overall fascicle comparison, broken down by 25/75 % (bar graphs)
  [x] tract scatter plot
  

From Phil, how to color the fascicles in dsi studio

**This might well be a suboptimal solution, but you can write a text file with one RGB triplet per fiber. In the GUI this is done from the "Tracts Misc" menu "save tract colors". From the command line you'd need to count the tracts in the file and then write the text out in a script.
You can use the command line to open the GUI with the tracts and associated color files.
It might be worth asking on the DSI Studio user group if nobody else here has a better solution. Frank is very responsive and adds improvements all the time, so my convoluted way might already be out of date**

#### 20220812
- added code to look at mean volume (not just proportion) over all fascicles
- looking at the maps w/volume, really hard to see differences b/c CC is just so much bigger than everything else
- for funsies, did a subtraction between nondep/dep prop and volume masks - these give cool pictures and really make it clear that there is more right sided disease
```{bash}
3dcalc -a fascicle_prop_dep_max.nii.gz -b fascicle_prop_nondep_max.nii.gz -expr 'a-b' -prefix dep_gr_nondep_prop_max.nii.gz
3dcalc -a fascicle_prop_dep_sum.nii.gz -b fascicle_prop_nondep_sum.nii.gz -expr 'a-b' -prefix dep_gr_nondep_prop_sum.nii.gz
3dcalc -a fascicle_vol_dep_max.nii.gz -b fascicle_vol_nondep_max.nii.gz -expr 'a-b' -prefix dep_gr_nondep_vol_max.nii.gz
3dcalc -a fascicle_vol_dep_sum.nii.gz -b fascicle_vol_nondep_sum.nii.gz -expr 'a-b' -prefix dep_gr_nondep_vol_sum.nii.gz
```

Steps to do the dsi studio things
- Design color system where each proportion is mapped to an RGB scheme
  - Okay, so red is 255, 0, 0
  - Yellow is 255,255,0
  - So to get the scale I want, I need to only alter the 255. 
  - If I want to do this in proportions, it means that there need to be 100 increments, each corresponding to a proportion
  - So 255/100, means every increment of 2.55 will equal 1 increment of proportion. So, to get the green color, take the proportion, multiply by 100 to get it into whole numbers, multiply * 2.55, round
  - i.e. if the proportion of overlay is 0.02, that means that it is 2% total. 2% * 2.55 = 5.1 -> round, 5. New RGB color is 255 5 0
  
  
- For each fascicle, count the # of streamlines. This will become number of rows in color file
- For each fascicle, make a file in the style Superior_Longitudinal_Fasciculus3_R_color.txt, with each row containing the RGB color scheme, space separated, with # of rows corresponding to number of fibers in fascicle
- alternatively, could have two types of files, file 1 with fascicle/rgb mapping, file type 2 would be each fascicle with color written out. Then could use perl to extra the 3 items, replace them, write to new file, and then overwrite initial file.

- looking for command line to get count of each file name
- dsi_studio --action=rec --source=*.src.gz --rotate_to=dwi_sum.nii.gz --save_nii=*_aligned.nii.gz

- to get fascicle full names, I went to DSI github (https://github.com/frankyeh/DSI-Studio/issues/72), and found this list:

Arcuate_Fasciculus_L Arcuate_Fasciculus_R Cingulum_Frontal_Parahippocampal_L Cingulum_Frontal_Parahippocampal_R Cingulum_Frontal_Parietal_L Cingulum_Frontal_Parietal_R Cingulum_Parahippocampal_Parietal_L Cingulum_Parahippocampal_Parietal_R Cingulum_Parahippocampal_L Cingulum_Parahippocampal_R Cingulum_Parolfactory_L Cingulum_Parolfactory_R Frontal_Aslant_Tract_L Frontal_Aslant_Tract_R Inferior_Fronto_Occipital_Fasciculus_L Inferior_Fronto_Occipital_Fasciculus_R Inferior_Longitudinal_Fasciculus_L Inferior_Longitudinal_Fasciculus_R Middle_Longitudinal_Fasciculus_L Middle_Longitudinal_Fasciculus_R Parietal_Aslant_Tract_L Parietal_Aslant_Tract_R Superior_Longitudinal_Fasciculus1_L Superior_Longitudinal_Fasciculus1_R Superior_Longitudinal_Fasciculus2_L Superior_Longitudinal_Fasciculus2_R Superior_Longitudinal_Fasciculus3_L Superior_Longitudinal_Fasciculus3_R Uncinate_Fasciculus_L Uncinate_Fasciculus_R Vertical_Occipital_Fasciculus_L Vertical_Occipital_Fasciculus_R Corticospinal_Tract_L Corticospinal_Tract_R Corticostriatal_Tract_Anterior_L Corticostriatal_Tract_Anterior_R Corticostriatal_Tract_Posterior_L Corticostriatal_Tract_Posterior_R Corticostriatal_Tract_Superior_L Corticostriatal_Tract_Superior_R Thalamic_Radiation_Anterior_L Thalamic_Radiation_Anterior_R Thalamic_Radiation_Posterior_L Thalamic_Radiation_Posterior_R Thalamic_Radiation_Superior_L Thalamic_Radiation_Superior_R Fornix_L Fornix_R Optic_Radiation_L Optic_Radiation_R Reticular_Tract_L Reticular_Tract_R Corpus_Callosum_Forceps_Minor Corpus_Callosum_Body Corpus_Callosum_Tapetum Corpus_Callosum_Forceps_Major

I stuck it in a file and used a perl command to make it look pretty

```{bash}
cd /Users/eballer/BBL/msdepression/dti/HCP_YA1065_tractography
vim fascicle_full_names

#copied values in there and closed out
more fascicle_full_names | perl -pe 's/ /\n/g' > fascicle_full_names_formatted


```

Now looks like this (but only 56 fascicles), so not right list:
Arcuate_Fasciculus_L
Arcuate_Fasciculus_R
Cingulum_Frontal_Parahippocampal_L
Cingulum_Frontal_Parahippocampal_R
Cingulum_Frontal_Parietal_L
Cingulum_Frontal_Parietal_R
Cingulum_Parahippocampal_Parietal_L
Cingulum_Parahippocampal_Parietal_R
Cingulum_Parahippocampal_L
Cingulum_Parahippocampal_R
Cingulum_Parolfactory_L
Cingulum_Parolfactory_R
Frontal_Aslant_Tract_L
Frontal_Aslant_Tract_R
Inferior_Fronto_Occipital_Fasciculus_L
Inferior_Fronto_Occipital_Fasciculus_R
Inferior_Longitudinal_Fasciculus_L
Inferior_Longitudinal_Fasciculus_R
Middle_Longitudinal_Fasciculus_L
Middle_Longitudinal_Fasciculus_R
Parietal_Aslant_Tract_L
Parietal_Aslant_Tract_R
Superior_Longitudinal_Fasciculus1_L
Superior_Longitudinal_Fasciculus1_R
Superior_Longitudinal_Fasciculus2_L
Superior_Longitudinal_Fasciculus2_R
Superior_Longitudinal_Fasciculus3_L
Superior_Longitudinal_Fasciculus3_R
Uncinate_Fasciculus_L
Uncinate_Fasciculus_R
Vertical_Occipital_Fasciculus_L
Vertical_Occipital_Fasciculus_R
Corticospinal_Tract_L
Corticospinal_Tract_R
Corticostriatal_Tract_Anterior_L
Corticostriatal_Tract_Anterior_R
Corticostriatal_Tract_Posterior_L
Corticostriatal_Tract_Posterior_R
Corticostriatal_Tract_Superior_L
Corticostriatal_Tract_Superior_R
Thalamic_Radiation_Anterior_L
Thalamic_Radiation_Anterior_R
Thalamic_Radiation_Posterior_L
Thalamic_Radiation_Posterior_R
Thalamic_Radiation_Superior_L
Thalamic_Radiation_Superior_R
Fornix_L
Fornix_R
Optic_Radiation_L
Optic_Radiation_R
Reticular_Tract_L
Reticular_Tract_R
Corpus_Callosum_Forceps_Minor
Corpus_Callosum_Body
Corpus_Callosum_Tapetum
Corpus_Callosum_Forceps_Major

#### 20220819
Try the within/between without cc
make talk pretty

#### 20220823
[x] sarah weinstein about network enrichment on slack
[x] scale by number of fibers in the depression network vs outside, rather than by fascicle. - works p < 2.2 *10^-16

#### 20220824
[x] keep talking with sarah
  - Sarah and Taki like option three (sum all disease within each network, divide by size of network)
[x] double check that wilcoxon is the right test to do given non normality. 
[x] there are 2 people who have no disease at all on their scans. WIll check them, but it is possible that I should remove them, maybe the mimosa step broke.
  - if i exclude those two people, findings are interesting - total overall volume lost not different between groups (p=0.06). Depression (p=0.046), nondepressed people = 0.096)
  - I did check, they do have mimosas, but the mimosas seem to be in perhaps cranial nerve areas. I am going to keep as is for now.
[] make clean notebook. Current one is excessive.

#### 20220825
[x] figure out how to do interaction
       - need a data frame with two colums, diagnosis (1s and 2s), and dep network (1s and 2s). What is the measure? 
       - Diagnosis    Dep Network   Proportion     Person
           1            1               .39           1
           1            2               .61           1
           2            1               .22           2
           2            2               .34           2
           
           model:
           proportion disease ~ diagnosis*dep_net + (1 | person)
[x] bart decided he wanted to do binomial instead of linear, realize that this is quite unstable given how big the numbers are
- tried with a scale factor
- tried 100000 and 10000, they give VERY big differences (i.e. dividing the number of total voxels in the network divided by the scale)
- might be related to the false consideration that each voxel is independent, and the size of the data
- in the end, will probably just do the linear model
- everyone got greedy

GOING BACK TO JUST LMER

#### 20220826
[] colors 
  - redownloaded dsistudio from frank. Currently, fascicles need to have colors manually added
  - script to make individual files for colors (rscript make_red_to_yellow_RGB_color_scheme.R)
  - Also, if you give load a table with multiple lines, it will assign it to multiple fascicles in order! So I am just going to also just output the RGB values into a spreadsheet for reading in. 
    [x] made table wmake_red_to_yello_RBG_color_scheme
    [x] in dsi studio, added each tract manually
      [x] double checked TWICE that fascicle order from fascicle_mean_proportion_overlap_nfasc_77_fascicle_names.txt is the same order that the fascicles are loaded in /Users/eballer/BBL/msdepression/templates/dti
      [x] saved it All_77_tracts_no_cranial_nerves.gz.txt
      [x] loaded colors (tracts misc/open cluster colors), navigate to /Users/eballer/BBL/msdepression/templates/dti/colors, and selected: fascicle_mean_proportion_overlap_nfasc_77_rgb.txt
      [x] looked at the pretty pictures!, red is lower proportion, yellow is higher proportion
      [x] wow, so pretty! Challenge is that it assumes there are equal values from 0-1, so if the max is low, it scales incorrectly. Will try to set max to be the max proportion, and scale based on that.
      [x] now you can scale!
*********
  - To open the collection of fascicles: in dsistudio, in t3D tracts (right next to autotracking), click the button. 
  - open /Users/eballer/BBL/msdepression/templates/dti/colors/All_77_tracts_colored_by_overlap_w_dep_map.tt.gz
  - it gives you each cluster in order, labeled 0 through 76. These were cross referenced with size of the named fascicles to confirm THEY ARE IN ORDER OF RGB MAPS
  
  **********
  - Another way to do this
      - Open dsistudio
      - click on fib file to open: /Users/eballer/BBL/msdepression/templates/dti/1904002815.src.gz.odf8.f5.gqi.1.25.fib.gz
      - once in studio, in t3d on right hand corner, click the folder
      - open /Users/eballer/BBL/msdepression/templates/dti/colors/All_77_tracts_colored_by_overlap_w_dep_map.tt.gz (should load in the order I want)
      - click each of the boxes
      - confirm order is what I want
      - load colors : tracts misc -> open cluster colors -> 
                -/Users/eballer/BBL/msdepression/templates/dti/colors, and selected: fascicle_mean_proportion_overlap_nfasc_77_rgb.txt (or whatever color I want)
                - available color maps at this time (constructed in make_red_to_yellow_RGB_color_scheme):
                "fascicle_mean_proportion_overlap_nfasc_77", "fascicle_proportion_overlap_with_depression_network_n77"
  *********
  
***********
   - Now just need to find a way to make a color scale like in afni, a bar of sorts
[x] made separate spreadsheet for fascicles and their overlap with the depression network so I could get colors for them
``` {r writing}
#line 660 through 664 msdepression_n380_started_20220726

just_fascicle_and_proportion <- fascicle_values_dep_no_cranial_nerves %>% dplyr::select(fascicle, prop_in_mask)

write.table(file = paste0(homedir, "/results/fascicle_proportion_overlap_with_depression_network_n77.csv"), x = just_fascicle_and_proportion, sep = ",", row.names = F, col.names = FALSE, quote=F)

```

[x] promis - updated, everything looks good, fatigue not different, all other findings going in expected direction, physical and mental health are now different

``` {r make_red_to_yellow_RGB_color_scheme.R}
#### Welcome to make_red_to_yellow_RGB_color_scheme! ####

### I developed this script because I wanted to make my own RGB color palettes for DSI studio. 
### In short, I want to color each fascicle to be its proportion of loss, scaled on the RGB scale
### In order to do this, I needed to figure out how to map my proportions to RGB

### Pre: File of proportions
### Post: Output of RGB values in Red to Yellow Scale for the Proportions
### Uses: Step 0: Figure out how to scale from red to yellow 
###           - Red = 255 0 0, yellow 255 255 0
###           - Means that we need to vary the middle value (255) to get where we need to be
###       Step 1) For red to yellow, calculate the step (i.e. how much each value will be)
###             - because my proportions are out of 1, I wanted each step to be 1/100
###             - I am setting this value as "max", so it could vary if you have another max #
###       Step 2) Multiply the proportion by 100, so now each count is 1-100, in percents
###       Step 3) Multiply the percent by the step
###       Step 4) Save this value in that fascicle, 255 [new_value] 0
###
### Dependencies: Any R will do

###
homedir="/Users/eballer/BBL/msdepression/"

files = c("fascicle_mean_proportion_overlap_nfasc_77", "fascicle_proportion_overlap_with_depression_network_n77")

for (filename in files) {
  #suffix
  suffix = paste0("_", filename, "_RGB")
  
  #read in file with fascicle name and proportion
  fascicle_name_and_prop <- read.csv(paste0(homedir, "/results/", filename, ".csv"), sep = ",", header = F)
  names(fascicle_name_and_prop) <- c("fascicle", "proportion")
  
  #set scale dynamically
  #highest possible number in scale
  max<-100 * max(fascicle_name_and_prop$proportion)
  
  #step that each value in our scale will correspond to
  step<-255/max 
  
  # make a column for red
  red <- rep(x=255, times = 77)
  
  fascicle_name_and_prop$red <- red
  #multiply proportion column by 100, then by step, and round
  fascicle_name_and_prop$green<- round((fascicle_name_and_prop$proportion *100*step),0)
  
  #make column for blue
  blue <- rep(x=0, times = 77)
  fascicle_name_and_prop$blue=blue
  
  #sort based on proportion to check, it works! Lower values are associated with lower RGB
  #sorted <- fascicle_name_and_prop[order(fascicle_name_and_prop$proportion),]
  
  #make individual file colors for loading
  for (fascicle in 1:dim(fascicle_name_and_prop)[1]) {
    
    fascicle_name = fascicle_name_and_prop$fascicle[fascicle]
    fascicle_rgb = paste0(fascicle_name_and_prop$red[fascicle], " ", fascicle_name_and_prop$green[fascicle], " ", fascicle_name_and_prop$blue[fascicle])
    print(paste0(fascicle_name, " ", fascicle_rgb))
    write.table(file = paste0(homedir, "templates/dti/colors/", fascicle_name, suffix,".txt"), x = fascicle_rgb, quote = FALSE, col.names = FALSE, row.names = FALSE)
    
  }
  
  #output color file (77 lines, each represents a color), and color name vector. Not sure how to do 1:1 assignments rather than manually, but I'll see if I can figure that out!
  fascicle_name_and_prop_rgb_only <- fascicle_name_and_prop %>%
    mutate(rgb = paste0(fascicle_name_and_prop$red, " ", fascicle_name_and_prop$green, " ", fascicle_name_and_prop$blue)) %>%
    dplyr::select(fascicle, rgb)
  
  write.table(file = paste0(homedir, "/templates/dti/colors/", filename, "_fascicle_names.txt"), x = fascicle_name_and_prop_rgb_only$fascicle, row.names = FALSE, col.names = FALSE, quote = FALSE)
  
  write.table(file = paste0(homedir, "/templates/dti/colors/", filename, "_rgb.txt"), x = fascicle_name_and_prop_rgb_only$rgb, row.names = FALSE, col.names = FALSE, quote = FALSE)
}
```


#### 20220830

[] 

[x] Talk about figures with Ted
  [] 1. Flow chart for patient selection (fig 1)
  [] 2. Demographics (or just list in text, or make A with flow chart and B with demographics) (table 1)
  [] 3. Pipeline figure
  [] 4. Two part image of depression network
    [] a: Rank of fascicles by volume of overlap w/dep network (cortical rendering of depression network)
    [] b: DSI fascicle of volume of overlap w/network (how to scale for visualizations) (new hamphire forest in the fall colors)
  [] 5. In vs outside dep net
    a. pink and blue fascicle pcicture part B
    b. inside vs outside dep net violin
  [] 6. Diagnosis analysis
    a. no diff by lesion volum
    b. but difference in fascicle volume
  [] 7. Dep Network Interaction bar graph
    [] is it possible to have a 3 part figure? 
      - a. interaction graph
      - b. picture of A. In depressed patients, volume of disease in dep network in depressed patients in one color, volume of disease in non depressed network in another color, divided by overall network size; B. Same thing in nondepressed patients. All on same color scale so you can hopefully see brighter colors/contrast in depressed as compared to non-depressed
  [] 8. Depression network overlap 
    a. scatter
    b. Fascicles colored by effect size 

is there a way to make a graphic of the histogram? Like median prop overlap rather than mean? I think this would be nice

[] sensitivity analysis using a different cutoff (do top third or quintile).
 - made the quintile and tertile groups
 - double checked
   - names (15 in top quintile, 62 in bottom 4; 26 in top tertile, 51 in bottom tertile)
   - volume sums (top tert + bottom 2 tertiles = top quintile + bottom 4 quintiles)
   
  - Added columns in that big mutate command
  - checked analysis: wilcox disease within depression network versus outside, calcuated by taking a sum of the affected volume in the depression network for each person, and dividing by the size overall size of the depression network, repeating for non-depression network, and using those proportions as inputs. 
  
  - Great news! Works with tertiles and quintiles, more disease in depression network. 
  - With depression diagnosis, more disease consistently in depressed vs nondepressed
      - with tertiles, p < 0.05 in dep network, but not outside (trend)
      - with quintiles, p < 0.05 in both dep and non-dep network
  - haven't tested interaction, but seems fair to say that different ways of slicing the cake, depressed people always have more disease in depression network, sometimes also in nondep network, and that more disease in depressed vs nondepressed network
```{r sensitivity analyses}
 #### tertile/quintile

#p=2.2*10^16, top tertile prop vol affected = 0.420, bottom 2 tertiles = 0.298
msdisease_within_versus_outside_depression_network_wilcoxon_tertile <- wilcox.test(dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_top_tertile_by_network_size_sum, dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_bottom_tertiles_by_network_size_sum,paired = TRUE) 

#p=0.0328, dep = 0.4407, nondep = 0.387
msdisease_diagnostic_effects_wilcoxon_tertile <- wilcox.test(dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_top_tertile_by_network_size_sum[dep_and_healthy_groups_for_ICD_analysis$depGroupVar == 1], dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_top_tertile_by_network_size_sum[dep_and_healthy_groups_for_ICD_analysis$depGroupVar == 2]) 

#p=0.058, dep = 0.31, nondep= 0.28
msdisease_diagnostic_effects_wilcoxon_bottom_tertiles <- wilcox.test(dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_bottom_tertiles_by_network_size_sum[dep_and_healthy_groups_for_ICD_analysis$depGroupVar == 1], dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_bottom_tertiles_by_network_size_sum[dep_and_healthy_groups_for_ICD_analysis$depGroupVar == 2]) 

#p=2.2*10^-16, top quintile prop vol affected = 0.419, bottom 4 quintiles = 0.322
msdisease_within_versus_outside_depression_network_wilcoxon_quintile <- wilcox.test(dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_top_quintile_by_network_size_sum, dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_bottom_quintiles_by_network_size_sum,paired = TRUE) 

#p=0.0325, dep = 0.4411, nondep = 0.386
msdisease_diagnostic_effects_wilcoxon_quintile <- wilcox.test(dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_top_quintile_by_network_size_sum[dep_and_healthy_groups_for_ICD_analysis$depGroupVar == 1], dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_top_quintile_by_network_size_sum[dep_and_healthy_groups_for_ICD_analysis$depGroupVar == 2]) 

#p=0.048, dep = 0.34, nondep = 0.30
msdisease_diagnostic_effects_wilcoxon_bottom_quintiles <- wilcox.test(dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_bottom_quintiles_by_network_size_sum[dep_and_healthy_groups_for_ICD_analysis$depGroupVar == 1], dep_and_healthy_groups_for_ICD_analysis$proportion_volume_lost_bottom_quintiles_by_network_size_sum[dep_and_healthy_groups_for_ICD_analysis$depGroupVar == 2]) 

```

#### 20220831
[x] ping ted with updates re: sensitivity analysis and confirm that analyses are done

[x] make effect size graphics
[o] make graphics separating out depressed patients and non depressed patients 
   - the scaling I am using right now just isn't wide enough to give me the contrast I'd like. 


# Network = Dep_network

Diagnosis | Predicted |   group_col |       95% CI
--------------------------------------------------
        1 |      0.37 | Dep_network | [0.33, 0.40]
        2 |      0.42 | Dep_network | [0.39, 0.45]

# Network = Nondep_network

Diagnosis | Predicted |      group_col |       95% CI
-----------------------------------------------------
        1 |      0.32 | Nondep_network | [0.28, 0.35]
        2 |      0.35 | Nondep_network | [0.33, 0.38]

Adjusted for:
* subject = 0 (population-level)


   
#### 20220901
[] separate to make a clean document once confirm analyses w/Ted
  - making a better spreadsheet that separates out proportion and volume

```{r fiber_volumes_values}

#read in fiber volume values
fiber_volume_values <- read.csv(paste0(homedir, "templates/dti/HCP_YA1065_tractography/fiber_volume_values.csv"), sep=",", header = T)

#remove cranial nerves
fiber_volume_values_no_cranial_nerves <- fiber_volume_values %>% filter(fascicle %in% fascicle_names_no_cranial_nerves)

#extract data frame that only includes the fascicle proportion lost
df_fascicles_prop <- df_demo_and_fascicles[ , (names(df_demo_and_fascicles) %in% fascicle_names_no_cranial_nerves)]
df_everything_else <- df_demo_and_fascicles[ , !(names(df_demo_and_fascicles) %in% fascicle_names_no_cranial_nerves)]

#multiply each row by the vector of total volumes to extract volume of disease within fascicle
df_fascicles_volumes <- sweep(x = df_fascicles_prop, MARGIN = 2,                        # Sweep with Complex STATS
                  STATS = fiber_volume_values_no_cranial_nerves$volume_full, FUN = "*")

# change name of df_fascicle_volumes to have the suffix, and add a suffix for the proportion measures
names(df_fascicles_prop) <- fascicle_names_w_prop_suffix
names(df_fascicles_volumes) <- fascicle_names_w_vol_suffix


#combine back with data_fram
#df_demo_and_fascicle_volumes_full <- cbind(df_everything_else, df_fascicle_volumes)
df_demo_and_fascicles_prop_and_vol <- cbind(df_everything_else, df_fascicles_prop, df_fascicles_volumes )


```

  [x] THIS WAS DOUBLE CHECKED with a few spot checks
>df_demo_and_fascicles_prop_and_vol$CC_prop[4]
[1] 0.5956769
> df_demo_and_fascicles_prop_and_vol$CC_vol[4]
[1] 232672
> fiber_volume_values_no_cranial_nerves$volume_full[fiber_volume_values_no_cranial_nerves$fascicle=="CC"]
[1] 390601
> 0.5956769*390601
[1] 232672
> df_demo_and_fascicles_prop_and_vol$AF_L_prop[4]
[1] 0.1407772
> df_demo_and_fascicles_prop_and_vol$AF_L_vol[4]
[1] 5028
> fiber_volume_values_no_cranial_nerves$volume_full[fiber_volume_values_no_cranial_nerves$fascicle=="AF_L"]
[1] 35716
> 0.1407772*35716
[1] 5027.998

[] make interaction plot prettier
  - awaiting bart - no other feedback. Will need to do this manually
[x] try making fascicle maps in dsi studio with different fib template (that better maps onto the template we used (fib))
  - /Users/eballer/BBL/msdepression/templates/dsi/hcp1065.1mm.fib.gz
  - Open T3d 
  - Select all files in HCP_YA1065_tractography/ in each section, except for cranial nerves
    [x] association [x] cerebellum [x] projection [x] commissural
  [x] make sure in right order
  [x] click all the boxes
  [x] save as one big file
  - load color file -> tracts misc -> open cluster colors
  - save this file
  
[] make depression bold map - need to either apply a brain mask or chose slices selectively b/c of the whole template thing

[] Ted wants me to try for JAMA Neurology
- 3000 words
â‰¤5 tables and/or figures
Structured abstract
Key Points
Study Type
Follow EQUATOR Reporting Guidelines
Do not submit figures with more than 4 panels unless otherwise justified.
See the AMA Manual of Style for more guidance on figure types and components.

For JAMA Neurology, 5 figures:

  [] 1. Flow chart for patient selection (fig 1, required)
  [] 2. Demographics (or just list in text, or make A with flow chart and B with demographics) (table 1)
  [] 3. Pipeline figure (maybe will be e-file)
  [] 4. Two part image of depression network
    [] a: Rank of fascicles by volume of overlap w/dep network (cortical rendering of depression network)
    [] b: DSI fascicle of volume of overlap w/network (how to scale for visualizations) (new hamphire forest in the fall colors)
  [] 5. In vs outside dep net
    a. pink and blue fascicle pcicture part B
    b. inside vs outside dep net violin
  [] 6. Diagnosis analysis
    a. no diff by lesion volum
    b. but difference in fascicle volume
  [] 7. Dep Network Interaction bar graph
    [] is it possible to have a 3 part figure? 
      - a. interaction graph
      - b. picture of A. In depressed patients, volume of disease in dep network in depressed patients in one color, volume of disease in non depressed network in another color, divided by overall network size; B. Same thing in nondepressed patients. All on same color scale so you can hopefully see brighter colors/contrast in depressed as compared to non-depressed
  [] 8. Depression network overlap 
    a. scatter
    b. Fascicles colored by effect size 

Could prob combine 5,6, 7&8
1. flow chart
2. Pipeline
3. Depression network
4. In vs out network, diagnosis analysis
5. Interaction and scatter
 
FIGURE POTENTIAL
1. Flow chart
  - demographics (+- promis scores) e-file (?)
  - pipeline is e -file (can only have max 4 pt figure)
2. Making depression network 
  a: Cortical rendering of depression network
  b: DSI fascicle of volume of overlap w/network (how to scale for visualizations) (new hampshire forest in the fall colors)
3.  In vs outside dep net
    a. inside vs outside dep net violin
    b. pink and blue fascicle picture part B
4. Diagnosis analysis
    a. diff by lesion volume (violin)
    b. but difference in fascicle volume (violin)
        - just dep vs non dep (put stuff about within/outside network for each diagnostic group in text)
5. Dep Network Interaction bar graph
     a. interaction graph
     b. scatter (effect size by overlap)
     c. Fascicles colored by effect size 
     
     
#### 20220902
[] Cleaning script
  [] Sections
    [x] Initialize
    [x] read in data/subset
    [x] read in and handle promis scores, link to scan
    [x] Demographics
    [x] Define Depression Network
    [x] Network enrichment/disease within/outside depression network
    [x] Lesion Volume between diagnostic groups
    [x] Lesion burden between diagnostic groups
    [x] Interaction
    [x] Effect size x fascicle volume of overlap
    

#### 20220906
    [] Sensitivity Analyses
    


